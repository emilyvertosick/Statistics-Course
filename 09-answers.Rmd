```{r setup7, include=FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Set seed
set.seed(34634986)

# Load data

# Save out list of all files
all_data <-
  list.files(here::here("Data"), pattern = ".rds", recursive = TRUE) %>%
  map(~ glue::glue("Data/{..1}") %>% as.character())

# Give names to list (will be object names)
all_data_names <-
  map(all_data,
      ~ str_split(..1, "/") %>%
        unlist() %>%
        pluck(3) %>%
        str_replace(".rds", "")
  )
names(all_data) <- all_data_names

# Load all data to environment
list2env(map(all_data, readRDS), envir = .GlobalEnv)

```

# Assignment Answers

## Week 1

```{r loadpkgs1, echo = TRUE}

# Week 1: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 1: load data
lesson1a <- readRDS(here::here("Data", "Week 1", "lesson1a.rds"))

```

### lesson1a

**This is data for 386 patients undergoing surgery. What type of data (e.g. continuous, binary, ordinal, nonsense) are each of the variables?**

The dataset has 11 variables:

- "id" is clearly a hospital record number. It doesn’t matter what type of variable it is, because you only want to know the type of variable in order to summarize or analyze data, and you’d never want to analyze or summarize patient id.
- "sex" is a binary variable
- "age" is continuous
- "p1", "p2", "p3", "p4" are the pain scores after surgery. They only take integer values between 0 and 6. They would therefore typically regarded as categorical, and because they are clearly ordered (i.e. pain score of 6 is higher than one of 4) these variables can be described are ordinal. However, many statisticians, myself included, would think it perfectly reasonable to treat these variables as continuous. 
- "t": total pain score takes on values between 0 and 24 and can thus be considered continuous
- "x", "y" and "z": should you attempt to summarize a variable if you don’t know what it is? It is obvious for y, this is some kind of hospital location, and is a categorical variable. But what about x and z? As it happens, z looks ordinal but isn’t: it is blood group coded 1=o, 2=a, 3=b, 4=ab.

## Week 2

```{r loadpkgs2, echo = TRUE}

# Week 2: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 2: load data
lesson2a <- readRDS(here::here("Data", "Week 2", "lesson2a.rds"))
lesson2b <- readRDS(here::here("Data", "Week 2", "lesson2b.rds"))
lesson2c <- readRDS(here::here("Data", "Week 2", "lesson2c.rds"))
lesson2d <- readRDS(here::here("Data", "Week 2", "lesson2d.rds"))
lesson2e <- readRDS(here::here("Data", "Week 2", "lesson2e.rds"))

```

### lesson2a

**This is data from marathon runners: summarize age, sex, race time in minutes (i.e. how long it took them to complete the race) and favorite running shoe.**

Age is continuous and normally distributed (look at a graph or look at the centiles) and so it wouldn’t be unreasonable to describe age in terms of mean and standard deviation (SD) by using `lesson2a %>% skim(age)`: mean of `r round(skim(lesson2a$age)$numeric.mean, 0)` years, SD of `r round(skim(lesson2a$age)$numeric.sd, 1)`. By the way, don’t just copy the readout from R: this would give mean age as `r round(skim(lesson2a$age)$numeric.mean, 2)` and implies we are interested in age within a few days. 

Sex is binary: use `tbl_summary(lesson2a %>% select(sex))` to get percentages. But note that the person who prepared the data didn’t state how the variable was coded (someone with sex=1 is a woman or a man?). Now what you should do in this situation is ask, but here is another alternative:

```{r week2a}

# Summary statistics for race time, separately by sex
lesson2a %>%
  group_by(sex) %>%
  skim(rt)

```

So sex==0 are running faster than the sex==1 and it would not be unreasonable to assume that sex==1 means women. 

Race time is continuous and looks pretty normal. Yes the data are skewed by a single outlier (a race time of `r max(lesson2a$rt)` minutes) but the mean and median are pretty similar (`r round(mean(lesson2a$rt, na.rm = TRUE), 0)` v. `r median(lesson2a$rt)` minutes) and the 5th and 95th centile are very close to the values expected by adding or subtracting 1.64 times the SD from the mean (5th centile is `r round(quantile(lesson2a$rt, c(0.05)), 0)`, expected value using means and SD is `r round(mean(lesson2a$rt, na.rm = TRUE) - sd(lesson2a$rt, na.rm = TRUE)*1.64, 0)`; 95th centile actual and expected values are `r round(mean(lesson2a$rt, na.rm = TRUE) + sd(lesson2a$rt, na.rm = TRUE)*1.64, 0)` and `r round(quantile(lesson2a$rt, c(0.95)), 0)`). I would probably feel comfortable reporting a mean and SD if you wanted.

Favorite running shoe: `lesson2a %>% skim(shoe)` gives a mean of `r round(mean(lesson2a$shoe, na.rm = TRUE), 2)` and a median of `r median(lesson2a$shoe, na.rm = TRUE)`. If you reported these, you need therapy: shoe is a categorical variable and you should report the percentage of runners that favor each shoe.

AN ADDITIONAL IMPORTANT POINT: you should give the number of observations and the number of missing observations. n is 98 for all observations except for favorite running shoe, where there are 95 observations and 3 missing observations.

So here is a model answer, suitable for publication (assuming that sex==1 is coded as female.)

```{r week2b, echo = FALSE, results = 'asis', warning = FALSE, purl = FALSE}

lesson2a <-
  lesson2a %>%
  mutate(
    shoe = lvls_revalue(as_factor(shoe),
                        c("Asics", "New Balance", "Nike", "Saucony"))
  )

lesson2a %>%
  select(-tm, -id) %>%
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ({sd})"),
    label = list(age = "Age", sex = "Women",
                 rt = "Race time in minutes",
                 shoe = "Favorite Running Shoe")
  )

```

However, look at this.

```{r week2c, echo = FALSE, results = 'asis', warning = FALSE, purl = FALSE}

lesson2a %>%
  select(-tm, -id) %>%
  tbl_summary(
    label = list(age = "Age", sex = "Women",
                 rt = "Race time in minutes",
                 shoe = "Favorite Running Shoe")
  )

```

This really isn't much to distinguish between these tables. On the one hand using the mean and SD gives you more information (e.g. what proportion of patients are aged over 70?). On the other hand, I can't see anyone using a table 1 to do these types of calculation and the median and interquartile range give you some more immediately usable information (no multiplying by 1.64!).

### lesson2b

**Summarize average pain after the operation. Imagine you had to draw a graph of "time course of pain after surgery". What numbers would you use for pain at time 1, time 2, time 3, etc.?**

This is data on postoperative pain. You were asked to summarize average pain after the operation. This is continuous, so by looking at the histogram, you can see that the data look skewed. I would be tempted to use the median (`r median(lesson2b$t, na.rm = TRUE)`) and quartiles (`r quantile(lesson2b$t, na.rm = TRUE, c(0.25))`, `r style_sigfig(quantile(lesson2b$t, na.rm = TRUE, c(0.75)))`).

```{r week2d, warning = FALSE}

# Create histogram to assess whether data look skewed
ggplot(data = lesson2b,
       aes(x = t)) +
  geom_histogram()

```

However, using the mean and standard deviation doesn’t get you far off. For normal data, 50% of the observations are within two-thirds of a standard deviations of the mean. So the interquartile range predicted from the mean and SD would be `r round(mean(lesson2b$t, na.rm = TRUE), 1)` - `r round(sd(lesson2b$t, na.rm = TRUE), 1)`\*0.67 and `r round(mean(lesson2b$t, na.rm = TRUE), 1)` + `r round(sd(lesson2b$t, na.rm = TRUE), 1)`\*0.67 which gives you `r round(mean(lesson2b$t, na.rm = TRUE) - sd(lesson2b$t, na.rm = TRUE)*0.67, 1)` and `r round(mean(lesson2b$t, na.rm = TRUE) + sd(lesson2b$t, na.rm = TRUE)*0.67, 1)`. This is an interesting point: the data can look skewed (and if you are interested, a statistical test can tell you that the data are definitely non-normal) but it doesn’t make much of a difference in practice. 

You were then asked to imagine that you had to draw a graph of "time course of pain after surgery". What numbers would you use for time 1, time 2 etc? The first thing to note is that to draw the graph, which seems like a useful thing to do, you have to treat the data as continuous: you can’t really graph a table very easily. This is another illustration of how something that seems technically incorrect gives you useful approximations. Now that we have continuous data we have to decide whether to use medians or means. As it turns out, normality of the data isn’t even an issue. Here is what happens if you graph the median pain score at each time point.

```{r week2e, echo = FALSE, warning = FALSE, purl = FALSE}

# Reshape data
lesson2b_long <-
  lesson2b %>%
  pivot_longer(
    cols = -c(t),
    names_to = "time"
  ) %>%
  mutate(time = parse_number(time))

# Calculate median and mean at each timepoint
lesson2b_stats <-
  lesson2b_long %>%
  group_by(time) %>%
  summarize(
    median = median(value, na.rm = TRUE),
    mean = mean(value, na.rm = TRUE)
  )

# Graph median pain
ggplot(data = lesson2b_stats,
       aes(x = time, y = median)) +
  geom_line(col = "darkblue") +
  scale_x_continuous(name = "Time", breaks = c(0:10)) +
  scale_y_continuous(name = "Median Pain Score", breaks = seq(0, 3.5, by = 0.5))

```

This makes it seem that postoperative pain doesn’t change for four time points, then drops dramatically. 

A graph using means seems more illustrative of what is really going on.

```{r week2f, echo = FALSE, warning = FALSE, purl = FALSE}

# Graph mean pain
ggplot(data = lesson2b_stats,
       aes(x = time, y = mean)) +
  geom_line(col = "darkblue") +
  scale_x_continuous(name = "Time", breaks = c(0:10)) +
  scale_y_continuous(name = "Median Pain Score", breaks = seq(0, 3.5, by = 0.5))

```

### lesson2c

**This is data on 241 patients undergoing radical prostatectomy. Summarize age, stage, grade and PSA.**

One of the first things to look for here is missing data. If you type `lesson2c %>% skim()`, you’ll see that there is no missing data for age, 9 missing observations for PSA and 41 for grade. You will notice that the "stage" variable is not included here, because it is a character variable, not a numeric variable.

If you type `tbl_summary(lesson2c %>% select(stage))`, you'll see that all patients have a stage assigned (no "NA" values).

A second issue is how to characterize the categorical variables. There are 8 different stages represented, many with very small numbers (like 2 for T4 and T1B, 4 for T3). It generally isn’t very helpful to slice and dice data into very small categories, so I would consider grouping. For instance, we could group the T1s together, and group the T3 and T4 patients together to get something like:

```{r week2g, echo = FALSE, warning = FALSE, result = 'asis', purl = FALSE}

lesson2c <-
  lesson2c %>%
  mutate(
    stage_category =
      case_when(
        stage %in% c("T1A", "T1B", "T1C") ~ "T1",
        stage %in% c("T3", "T4") ~ "T3/4",
        TRUE ~ stage
      )
  )

lesson2c %>%
  select(stage_category) %>%
  tbl_summary(label = list(stage_category = "Stage"))

```

<br>

To get this table, I created a new variable called "stage_category".

The code below uses the `case_when` function, which is similar to the `if_else` function. Both functions take a condition and assign a value, but `if_else` can only assign two values (one if the condition is TRUE, the other if the condition is FALSE). `case_when` can assign as many values as you'd like.

In this case, the `case_when` function does the following:

1) When the value of "stage" is one of the values in the list of "T1A", "T1B", or "T1C", set the variable "stage_category" to "T1".
2) When the value of "stage" is "T3" or "T4", set the variable "stage_category" to "T3/T4".
3) In `case_when`, TRUE means "every observation that didn't fall into any of the previous categories". Here, this means: for all observations that didn't fit into the previously specified "T1" or "T3/4" categories, use the value of the variable "stage". In this case, these are the "T2A", "T2B" and "T2C" values, which remain the same in both the "stage" and "stage_category" variables.

```{r week2h, echo = TRUE}

# Create new variable for stage and save into "lesson2c" dataset
lesson2c <-
  lesson2c %>%
  mutate(
    stage_category =
      case_when(
        stage %in% c("T1A", "T1B", "T1C") ~ "T1",
        stage %in% c("T3", "T4") ~ "T3/4",
        TRUE ~ stage
      )
  )

# You can use the "count" function to confirm that your variable was created correctly
lesson2c %>% count(stage_category, stage)

```

There is a similar issue for grade, with few patients having grades 4, 5, 8 or 9. Now a key point is that what you decide to do in situations like this will often need to take into account your medical understanding. It might seems sensible to categorize grade as ≤6 or ≥7, or perhaps 4/5, 6, 7, 8/9. But as it turns out in prostate cancer, pathologists can’t reliably grade a cancer as 4 or 5 and these cancers should really be grouped with grade 6. Grade 8, on the other hand, signifies very aggressive disease and really needs to be reported separately even if there are only a few patients with grade 8. So grade would probably be summarized as per the following table:

```{r week2i, echo = FALSE, warning = FALSE, results = 'asis', purl = FALSE}

lesson2c %>%
  mutate(
    grade_category =
      case_when(
        grade <= 6 ~ 6,
        grade >= 8 ~ 8,
        TRUE ~ grade
      )
  ) %>%
  select(stage_category, grade_category, age, psa) %>%
  tbl_summary(
    label = list(
      stage_category = "Stage",
      grade_category = "Grade",
      age = "Age",
      psa = "PSA"
    )
  )

```

### lesson2d

**Summarize cost.**

I asked you to summarize the cost. You can see from a graph that the data are not normally distributed. If we were to follow the rule book slavishly, we would report a median and interquartile range. But what use is a median for cost data? We want to know "average" cost so that we can predict, for example, how much we should budget for next year. This requires a mean.

### lesson2e

**Summarize total cancer pain in one month in a group of chronic cancer patients.**

The data are grossly non-normal and you could use the median pain score with interquartile range. 

As for summarizing the number of days in pain, almost everyone has 31 days of pain. So I would give proportions of patients who had pain for 31 days and then the number who, say, had pain at least 3 out of every 4 days and 2 out of 4 days. There are two ways of doing this. You could use `tbl_summary(lesson2e %>% select(f), type = list(f = "categorical"))` and then combine some of the results. Or, and this is a little more complicated, you could create a new variable.


```{r week2j}

# Create variable to categorize number of days in pain
lesson2e <-
  lesson2e %>%
  mutate(
    days =
      case_when(
        f <= 15 ~ 0,
        f > 15 & f < 23 ~ 1,
        f > 23 & f < 31 ~ 2,
        f == 31 ~ 3
      )
  )

```

In other words, create a new variable called "days", and set it to 0 for anyone with 15 or less days of pain. Call anyone who has pain more than half the time (i.e. more than 15 days) a 1. Call anyone who has pain more than three quarter of the time (i.e. more than 23 days) a 2. Call anyone who has pain all the time a 3.

```{r week2k}

# Print formatted table summarizing number of days in pain
tbl_summary(
  lesson2e %>% select(days)
)

```

```{r week2l, echo = FALSE, results = "hide", purl = FALSE}

tbl_2e <-
  tbl_summary(
    lesson2e %>% select(days),
    statistic = list(days = "{p}%")
  )

```

So you could report that, of the `r sum(!is.na(lesson2e$days))` patients with data on number of days with pain, `r inline_text(tbl_2e, variable = "days", level = "3")` were in daily pain, `r inline_text(tbl_2e, variable = "days", level = "0")` of patients had pain on less than half of days, `r inline_text(tbl_2e, variable = "days", level = "1")` of patients had pain on more than half but less than 75% of days, `r inline_text(tbl_2e, variable = "days", level = "2")` of patients had pain on more than 75% of days, but not every day.

_For keen students only!_

You could also try a log transformation of the pain scores. Create a new variable using `log(pain)`.

```{r week2m}

# Create a variable for log of the pain score
lesson2e <-
  lesson2e %>%
  mutate(log = log(pain))

```

Analyze this variable and you’ll see it appears normally distributed.

The mean of log is `r round(mean(lesson2e$log, na.rm = TRUE), 2)`. You can transform the log back by calculating e^`r round(mean(lesson2e$log, na.rm = TRUE), 2)`^ (the function is ``exp(`r round(mean(lesson2e$log, na.rm = TRUE), 2)`)``) to get `r round(exp(mean(lesson2e$log, na.rm = TRUE)), 0)`, close to the median. Backtransforming the standard deviation is more complicated and can’t really be done directly. What you need to do is make any calculations you need on the log transformed scale and then backtransform the results. Imagine you wanted a 95% confidence interval. A 95% confidence interval is the mean ± 1.96 standard deviations. The standard deviation of the log data is close to one. So the confidence interval is `r round(mean(lesson2e$log, na.rm = TRUE) - 1.96*sd(lesson2e$log, na.rm = TRUE), 2)` to `r round(mean(lesson2e$log, na.rm = TRUE) + 1.96*sd(lesson2e$log, na.rm = TRUE), 2)`. Transforming this ``exp(`r round(mean(lesson2e$log, na.rm = TRUE) - 1.96*sd(lesson2e$log, na.rm = TRUE), 2)`)`` and ``exp(`r round(mean(lesson2e$log, na.rm = TRUE) + 1.96*sd(lesson2e$log, na.rm = TRUE), 2)`)`` gives a confidence interval on the original scale of `r round(exp(mean(lesson2e$log, na.rm = TRUE) - 1.96*sd(lesson2e$log, na.rm = TRUE)), 2)` and `r round(exp(mean(lesson2e$log, na.rm = TRUE) + 1.96*sd(lesson2e$log, na.rm = TRUE)), 2)`. This is a reasonable approximation to the 5th (`r round(quantile(lesson2e$pain, na.rm = TRUE, c(0.05)), 0)`) and 95th centile (`r round(quantile(lesson2e$pain, na.rm = TRUE, c(0.95)), 0)`).

## Week 3

```{r loadpkgs3, echo = TRUE}

# Week 3: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 3: load data
lesson3a <- readRDS(here::here("Data", "Week 3", "lesson3a.rds"))
lesson3b <- readRDS(here::here("Data", "Week 3", "lesson3b.rds"))
lesson3c <- readRDS(here::here("Data", "Week 3", "lesson3c.rds"))
lesson3d <- readRDS(here::here("Data", "Week 3", "lesson3d.rds"))
lesson3e <- readRDS(here::here("Data", "Week 3", "lesson3e.rds"))
lesson3f <- readRDS(here::here("Data", "Week 3", "lesson3f.rds"))

```

### lesson3a

**These are data from over 1000 patients undergoing chemotherapy reporting a nausea and vomiting score from 0 to 10.  Does previous chemotherapy increase nausea scores? What about sex?**

```{r week3a, include = FALSE, purl = FALSE}

n_fulldata <- 
  lesson3a %>%
  filter(!is.na(pc) & !is.na(nv)) %>%
  summarize(sum = nrow(.))

meanchemo <-
  lesson3a %>%
  filter(pc == 1 & !is.na(nv)) %>%
  summarize(n = nrow(.), mean = mean(nv, na.rm = TRUE), sd = sd(nv, na.rm = TRUE))

meannochemo <-
  lesson3a %>%
  filter(pc == 0 & !is.na(nv)) %>%
  summarize(n = nrow(.), mean = mean(nv, na.rm = TRUE), sd = sd(nv, na.rm = TRUE))

meanpct <-
  ((meanchemo %>% pull(mean) - meannochemo %>% pull(mean)) /
     meannochemo %>% pull(mean))*100

chemo_test <-
  t.test(nv ~ pc, data = lesson3a, paired = FALSE, var.equal = TRUE)

meanwomen <-
  lesson3a %>%
  filter(sex == 1 & !is.na(nv)) %>%
  summarize(n = nrow(.), mean = mean(nv, na.rm = TRUE), sd = sd(nv, na.rm = TRUE))

sextotal <-
  lesson3a %>%
  group_by(sex) %>%
  summarize(n = n())

sexmiss <-
  lesson3a %>%
  filter(is.na(nv)) %>%
  group_by(sex) %>%
  summarize(n = n())

meanmen <-
  lesson3a %>%
  filter(sex == 0 & !is.na(nv)) %>%
  summarize(n = nrow(.), mean = mean(nv, na.rm = TRUE), sd = sd(nv, na.rm = TRUE))

women_test <-
  t.test(nv ~ sex, data = lesson3a, paired = FALSE, var.equal = TRUE)

chi_test <-
  chisq.test(table(lesson3a$sex, !is.na(lesson3a$nv)), correct = FALSE)

```

Hands up, who typed in `t.test(nv ~ pc, data = lesson3a, paired = FALSE, var.equal = TRUE)` without looking at the data? There are lots of missing data. There is a question as to whether you would actually analyze these data at all: could data be missing because patients were too ill to complete questionnaires?  Could there have been bias in ascertaining who had prior chemotherapy?  If you do decide to analyze, a t-test would be appropriate (`t.test(nv ~ pc, data = lesson3a, paired = FALSE, var.equal = TRUE)` and `t.test(nv ~ sex, data = lesson3a, paired = FALSE, var.equal = TRUE)`). A model answer might be:

<div class="quote-container">

> Details of prior chemotherapy were available for `r pull(n_fulldata)` of the `r nrow(lesson3a)` patients with nausea scores. Mean nausea scores were approximately `r round(meanpct, -1)`% higher in the `r meanchemo %>% pull(n)` patients with prior experience of chemotherapy (`r round(meanchemo %>% pull(mean), 1)`; SD `r round(meanchemo %>% pull(sd), 2)`) than in the `r meannochemo %>% pull(n)` chemotherapy-naive patients  (`r round(meannochemo %>% pull(mean), 1)`; SD `r round(meannochemo %>% pull(sd), 2)`). The difference between groups was small (`r round(meanchemo %>% pull(mean) - meannochemo %>% pull(mean), 1)`, 95% C.I. `r round(abs(chemo_test$conf.int[[2]]), 1)`, `r round(abs(chemo_test$conf.int[[1]]), 1)`) but highly statistically significant (p`r style_pvalue(chemo_test$p.value)` by t-test), suggesting that prior chemotherapy increases nausea scores. Nausea scores were slightly lower in women (n=`r meanwomen %>% pull(n)`; mean `r round(meanwomen %>% pull(mean), 1)`; SD `r round(meanwomen %>% pull(sd), 2)`) than men (n=`r meanmen %>% pull(n)`; mean `r round(meanmen %>% pull(mean), 1)`; SD `r round(meanmen %>% pull(sd), 2)`) but there were no statistically significant differences between the sexes (difference between means `r round(meanmen %>% pull(mean) - meanwomen %>% pull(mean), 1)`, 95% C.I. `r round(women_test$conf.int[[1]], 1)`, `r round(women_test$conf.int[[2]], 1)`; p=`r style_pvalue(women_test$p.value)` by t-test). However, far more women (`r sexmiss$n[2]` / `r sextotal$n[2]`, `r round(sexmiss$n[2]/(sexmiss$n[1]+sexmiss$n[2])*100, 0)`%) than men (`r sexmiss$n[1]` / `r sextotal$n[1]`, `r round(sexmiss$n[1]/(sexmiss$n[1]+sexmiss$n[2])*100, 0)`%) failed provide a nausea score (p=`r style_pvalue(chi_test$p.value)` by chi squared), perhaps suggesting bias in reporting.

</div>

Now, I'll explain what I did. First, I did the two t-tests:

```{r week3b}

# t-test for nausea/vomiting by prior chemotherapy
t.test(nv ~ pc, data = lesson3a, paired = FALSE, var.equal = TRUE)

# t-test for nausea/vomiting by sex
t.test(nv ~ sex, data = lesson3a, paired = FALSE, var.equal = TRUE)

```

While the `t.test` function gives the confidence interval around the difference in means, it does not calculate the difference in means for you. While you can cut and paste to calculate this manually, you can do it by using the `tbl_summary` and `add_difference` functions from the {gtsummary} package.

```{r week3b2, warning = FALSE, message = FALSE}

tbl_summary(
  # Keep 2 variables of interest
  lesson3a %>%
    select(nv, pc),
  by = pc,
  # specify that you want mean (SD) rather than median (IQR)
  statistic = list(nv = "{mean} ({sd})")
) %>%
  # Use the "add_difference" function with the "ancova" test
  add_difference(
    test = list(nv = "ancova")
  )

```

As you can see, the table above gives the same estimates as the `t.test` function. The table also gives additional information including the number of observations in each group, the number of missing observations in each group, and the difference in means between the two groups.

Next I created a new variable for missing data on nausea and vomiting:

```{r week3c}

# Create new variable to indicate whether "nv" variable is missing
lesson3a <-
  lesson3a %>%
  mutate(
    missing =
      if_else(is.na(nv), 1, 0)
  )

```

And then created a table to look at the missingness for this variable:

```{r week3d, warning = FALSE}

# Formatted table to look at rates of missingness in "nv" variable by sex
tbl_summary(
  lesson3a %>% select(missing, sex),
  by = sex,
  type = list(missing = "categorical")
)

```

If you got that far: wow! (also, forget the course, you don’t need it). If you didn’t get that far, don’t feel bad about it, but try to get a handle on the thought process.

One other issue: the p-value for the first t-test (previous chemotherapy) is given as "p-value = 4.7e-06". While this number is very close to 0, we cannot round to 0 - there is no such thing as a p-value of 0 for any hypothesis worth testing (there is a small but finite chance of every possible result, even throwing 100,000 tails in a row on an unbiased coin.) So do not report "p=0.0000"! You can round p-values for reporting - for example, "4.7e-06" can be rounded to "<0.0005". As you can see, if you use the `tbl_summary` and `add_difference` functions from {gtsummary}, the p-value is automatically formatted in the table as "p<0.0001".

_For more advanced students:_

The other thing you can do is to find out the precise p-value from the t value (which is given above the p-value: -4.6275). The function you need is `pt(t value, degrees of freedom)`. This will give you the p-value for a one-sided test, so you must multiply by 2 to get the two-sided test p-value.

```{r week3e}

# Find out p-value from t value
pt(-4.6275, 510)*2

```

This p-value can also be read as `r round(pt(-4.6275, 510)*2*10^6, 1)` x 10^-6^. An interesting question though: is it important whether p is <0.0005 or `r round(pt(-4.6275, 510)*2*10^6, 1)` x 10^-6^?

What is "degrees of freedom" and how come it is `r t.test(nv ~ pc, data = lesson3a, var.equal = TRUE)$parameter`? Think about it this way: You have a line of ten people outside your door. You know the mean age of this group. Each person comes in one-by-one, you try to guess their age and they tell you how old they actually are. As each person comes in, your guesses will get better and better (for example, if the first three people have ages less than the mean, you will guess the age of the fourth person as something above the mean). However, only when you have the ages of the first nine people will you be able to guess for sure the age of the next (and last) person. In other words, the ages of the first nine people are "free", the age of the last person is "constrained". So "degrees of freedom" is the sample size minus one. Little catch though: for an unpaired test (such a straight drug v. placebo trial), you have two different groups and two different means. You would therefore be able to predict the scores of two observations (the last patient in each group). Degrees of freedom in an unpaired test is therefore the total sample size minus two (or, put another way, the sample size in group a minus one plus the sample size in group b minus one).

### lesson3b

**Patients with wrist osteoarthritis are randomized to a new drug or placebo. Pain is measured before and after treatment. Is the drug effective?**

The most obvious thing to do would be to do:

```{r week3f}

# t-test for pain after treatment, by group
t.test(p ~ g, data = lesson3b, paired = TRUE, var.equal = TRUE)

```

This gives a p-value of `r style_pvalue(t.test(p ~ g, data = lesson3b, var.equal = TRUE)$p.value)` and you might conclude that although the difference wasn't statistically significant, there was some evidence that the drug works. However, this t-test assumes that the data are independent. In the present case, this assumption does not hold: each patient contributes data from two wrists, and the pain scores from each wrist are correlated. There are several ways around the problem. The most obvious is to say: "These data are not independent, I am not going to analyze them. Call in a statistician."

However, if you are really keen, you could try the following:

You could analyze the data from each wrist separately by creating new variables as shown below (lines with # are comments). Since the "before" and "after" measurements are coming from the same patient, we will need to use a paired t-test here.

```{r week3g}

# Analyze data separately by wrist
lesson3b <-
  lesson3b %>%
  # Create a new variable called "pright" equivalent to "p"
  # (the pain score for the right wrist (site 2) only)
  mutate(
    pright = case_when(site == 2 ~ p)
    # By default, any observations that do not fall into the specified conditions
    # in the "case_when" statement will be set to missing (NA)
  ) %>%
  # Create a new variable called "pleft" for pain scores for the left wrist
  mutate(
    pleft = case_when(site == 1 ~ p)
  )

# t-test for pain in right and left wrists separately
t.test(pright ~ g, data = lesson3b, paired = TRUE, var.equal = TRUE)
t.test(pleft ~ g, data = lesson3b, paired = TRUE, var.equal = TRUE)

```

You could also analyze the data by taking the average of the two wrists. You can create a new value for the average using the `mean` function. The `distinct` function from the {dplyr} package allows you to drop duplicate observations. Since there are two observations per patient (one for the left wrist and one for the right wrist), we will take the average and then drop the duplicate observation so that each patient is included only once.

```{r week3h}

lesson3b_avg <-
  lesson3b %>%
  # Grouping by "id" so that each patient ends up with the average of their own two wrist scores
  group_by(id) %>%
  # Calculate the mean pain score between wrists for each patient
  mutate(
    meanpain = mean(p, na.rm = TRUE)
  ) %>%
  # Only keep the patient ID, group variable and mean pain score
  select(id, g, meanpain) %>%
  # Drop duplicates so you don't count each patient twice
  # Here we only want one observation per patient since we are assessing the average pain between the two wrists
  distinct() %>%
  # Ungroup the data
  ungroup()

# t-test for average pain between both wrists
t.test(meanpain ~ g, data = lesson3b_avg, paired = TRUE, var.equal = TRUE)

```

### lesson3c

**Some postoperative pain data again. Is pain on day 2 different than pain on day 1? Is pain on day 3 different from pain on day 2?**

The most obvious issue here is that you are measuring the same patients on two occasions, so you are going to want a paired test. Should you do a paired t-test? Many statisticians would prefer a non-parametric method given that the data take only five different values and that the number of observations is small. The following command gives you the "Wilcoxon signed rank test":

```{r week3i}

# Non-parametric test comparing day 1 and day 2 pain
wilcox.test(lesson3c$t1, lesson3c$t2, paired = TRUE)

```

If you run this code, you will notice you get a warning in yellow text that states that the "exact p-value" cannot be calculated. In R, "warnings" are notes that indicate you may want to look more closely at your code, but won't stop the code from running - as you can see, this code still gives a p-value - but R is also flagging this result to tell you that this is not an "exact" p-value (you will learn more about exact p-values later). You should always take note of warnings when they occur, but sometimes you may not need to make any changes to the code.

(By the way: I know this because that is what it says on the read out. If you had asked me yesterday, I doubt I would have remembered the name of a non-parametric paired test, another reason to think in concepts rather than remembering statistical techniques). The p-value you get is p=`r style_pvalue(wilcox.test(lesson3c$t1, lesson3c$t2, exact = FALSE, paired = TRUE)$p.value)`. We cannot conclude that pain scores are different. But is that all we want to say? The number of patients is small, maybe we failed to spot a difference. So let’s try a t-test:

```{r week3j}

# paired t-test comparing day 1 and day 2 pain
t.test(lesson3c$t1, lesson3c$t2, paired = TRUE, var.equal = TRUE)

```

The p-value you get (p=`r style_pvalue(t.test(lesson3c$t1, lesson3c$t2, var.equal = TRUE, paired = TRUE)$p.value)`) is very similar to the non-parametric method and you get a confidence interval for the difference between means of `r style_sigfig(t.test(lesson3c$t1, lesson3c$t2, var.equal = TRUE, paired = TRUE)$conf.int[[1]])`, `r style_sigfig(t.test(lesson3c$t1, lesson3c$t2, var.equal = TRUE, paired = TRUE)$conf.int[[2]])`. What I would conclude from this is that pain is unlikely to be worse on day 2 than day 1 but any decrease in pain is probably not important. 

What about normality of the data? Doesn’t that figure into whether you assess by t-test or non-parametric? Well if you type look at the distribution of t1 and t2, you find that neither are normally distributed. But a paired t-test does not depend on the assumption that each set of data in a pair is distributed but that the differences between pairs are normally distributed. So you would have to create a new variable and look at that:

```{r week3k}

# Create a variable containing the difference in pain scores between days 1 and 2
lesson3c <-
  lesson3c %>%
  mutate(delta12 = t2 - t1)

# Summarize change in pain scores
skim(lesson3c$delta12)

```

As it turns out, the distribution of differences between pain scores are normally distributed even though pain at time 2 does not have a normal distribution. In fact, this is almost always the case. 

Now let's compare t2 and t3. Again, no significant difference. Does this mean that pain does not decrease after an operation? Of course, we know that pain does indeed get better. This illustrates two points: first, don't ask questions you know the answer to; second, asking lots of questions (is pain on day 2 better than on day 1?; is pain on day 3 better on day 2?) is not as good as just asking one question: does pain decrease over time? We'll discuss how to answer this question later on in the course.

### lesson3d

**This is a single-arm, uncontrolled study of acupuncture for patients with neck pain. Does acupuncture increase range of motion?  Just as many men as women get neck pain. Can we say anything about the sample chosen for this trial with respect to gender? The mean age of patients with neck pain is 58.2 years. Is the trial population representative with respect to age?**

This is before and after data, so again you’ll want a paired test. The data are continuous, so a paired t-test is an option (if you are worried about normality, do both the parametric and non-parametric test and compare the results.)

There are two ways of doing the t-test:

1) Test whether the baseline scores are different from the post-treatment scores:

```{r week3l}

# paired t-test for before and after pain scores
t.test(lesson3d$b, lesson3d$a, paired = TRUE, var.equal = TRUE)

```

2) Test whether the difference between scores is different from zero:

```{r week3m}

# t-test for whether difference between before and after scores is different than zero
t.test(lesson3d$d, mu = 0)

```

Both methods give you an identical p-value of `r style_pvalue(t.test(lesson3d$d, mu = 0)$p.value)`. But note, I didn’t ask for the p-value. I asked "Does acupuncture increase range of motion?" Given that this is an uncontrolled trial, it may be that range of motion has improved naturally over time. So in fact you can’t answer the question about whether acupuncture increases range of motion from these data!

BTW: for those who are interested, acupuncture has been shown to improve neck pain and range of motion in a controlled trial, see: [Irnich, Behrens et al., Immediate effects of dry needling and acupuncture at distant points in chronic neck pain: results of a randomized, double-blind, sham-controlled crossover trial.](https://www.ncbi.nlm.nih.gov/pubmed/12237186)

```{r week3n}

# Test whether proportion of women is different from 50%
binom.test(sum(lesson3d$sex), nrow(lesson3d %>% filter(!is.na(sex))), p = 0.5)

```

Only about a quarter of the patients are women, and the binomial test gives a p-value of `r style_pvalue(binom.test(sum(lesson3d$sex), nrow(lesson3d), p = 0.5)$p.value)`, suggesting that men are over-represented in this trial. But is this important?

```{r week3o}

# t-test for whether age is significantly different from 58.2
t.test(lesson3d$age, mu = 58.2)

```

Similarly, this t-test for age gives a p-value of `r style_pvalue(t.test(lesson3d$age, mu = 58.2)$p.value)`, but I doubt anyone would call a mean age of 52 much different from a mean age of 58, so you’d probably want to say that, ok, the trial patients are younger than we might expect, but not by much.

### lesson3e

**These data are length of stay from two different hospitals. One of the hospitals uses a new chemotherapy regime that is said to reduce adverse events and therefore length of stay. Does the new regime decrease length of stay?**

Well, before running off and doing t-tests, let’s have a look at the data: 

```{r week3p, warning = FALSE}

# Summarize data by hospital
lesson3e %>%
  group_by(hospital) %>%
  skim()

```

This shows us the mean, median, etc. for length of stay by hospital. The two sets of data look very similar. Regardless of whether we do a t-test or non-parametric test, we do not see a difference between groups, p is `r style_pvalue(t.test(los ~ hospital, data = lesson3e, var.equal = TRUE, paired = FALSE)$p.value)` or `r style_pvalue(wilcox.test(los ~ hospital, data = lesson3e, exact = FALSE, paired = FALSE)$p.value)`. Interesting question: should you report a 95% confidence interval for the difference between groups? This shows, for example, that the new regimen could reduce length of stay by up to six days, surely important in cost terms. On the other hand, this is not a randomized trial. There might be all sorts of differences between the hospitals other than the different chemotherapy regime, such as the mix of patients, discharge policies etc. So you would have to be careful in stating that the chemotherapy regime "could reduce hospital stay by as much as six days" or some such. 

For advanced students only:

The data are non-normally distributed so you could try a log transform: 

```{r week3q}

# Create variable for log of length of stay
lesson3e <-
  lesson3e %>%
  mutate(loglos = log(los))

```

The distribution of this new variable for both groups combined is normal, therefore data in each group will be normal. Try a t-test:

```{r week3r}

# paired t-test using log of length of stay as outcome
t.test(loglos ~ hospital, data = lesson3e, paired = FALSE, var.equal = TRUE)

```

```{r week3s, include = FALSE, purl = FALSE}

log_test <- t.test(loglos ~ hospital, data = lesson3e, paired = FALSE, var.equal = TRUE)

log_diff <- log_test$estimate[[1]] - log_test$estimate[[2]]

```

The p-value is similar to the untransformed analyses. Now, look at the difference between means `r style_sigfig(log_test$estimate[[1]] - log_test$estimate[[2]])` and 95% confidence interval (`r style_sigfig(log_test$conf.int[[1]])`, `r style_sigfig(log_test$conf.int[[2]])`).

To backtransform these values, you have to remember that addition on a log scale is the same as multiplication on an untransformed scale. Backtransform `r style_sigfig(log_diff)` using ``exp(`r style_sigfig(log_diff)`)`` and you get `r style_sigfig(exp(log_diff))`. In other words, length of stay in hospital a is `r style_sigfig(exp(log_diff)*100)`% more (or `r style_sigfig(100 - exp(log_diff)*100)`% less) compared to hospital b. Do the same things with the upper and lower bounds of the confidence interval and you might conclude that the difference in length of stay is between `r style_sigfig(100 - exp(log_test$conf.int[[1]])*100)`% less in hospital a to `r style_sigfig(abs(100 - exp(log_test$conf.int[[2]])*100))`% less in hospital b. If you wanted to convert these numbers to actual days, just multiply by the mean hospital stay in group b by `r style_sigfig(exp(log_test$estimate[[1]] - log_test$estimate[[2]]))`, `r style_sigfig(exp(log_test$conf.int[[1]]))` and `r style_sigfig(exp(log_test$conf.int[[2]]), digits = 3)`.

### lesson3f

**These data are from a randomized trial on the effects of physiotherapy treatment on function in pediatric patients recovering from cancer surgery. Function is measured on a 100 point scale. Does physiotherapy help improve function?**

You will want to do an unpaired t-test or non-parametric test on these data. 

```{r week3t}

# unpaired t-test for change in pain by physiotherapy group
t.test(delta ~ physio, data = lesson3f, paired = FALSE, var.equal = TRUE)

```

```{r week3u, echo = FALSE, purl = FALSE}

physio_test <- t.test(delta ~ physio, data = lesson3f, paired = FALSE, var.equal = TRUE)

meansd1 <- lesson3f %>% filter(physio == 1) %>% summarize(mean = mean(delta, na.rm = TRUE), sd = sd(delta, na.rm = TRUE))

meansd2 <- lesson3f %>% filter(physio == 0) %>% summarize(mean = mean(delta, na.rm = TRUE), sd = sd(delta, na.rm = TRUE))

```

This gives a p-value of `r style_pvalue(physio_test$p.value)` (incidentally, don't say "p > 0.05" or "p=`r style_sigfig(physio_test$p.value, digits = 4)`", which are under- and over-precise, respectively). Given a p-value greater than 5%, we would say that we found no evidence that the treatment was effective. But is this really the case? Look at the read out from the t-test again, particularly the means for each group and the difference. The improvements in the treatment group was about 50% greater than in controls. The 95% confidence interval for the difference includes a possible `r style_sigfig(abs(physio_test$conf.int[[1]]))` point improvement on physiotherapy, more than twice that of controls. So physiotherapy might well be a clinically important treatment in this population, even if we failed to prove it was better than control in this trial. Whatever your conclusion, don’t just report the p-value: report the means and standard deviations in each group separately plus the difference between means and a 95% confidence interval. If I was writing this up for a journal, I might say:

<div class="quote-container">

>Mean improvement in function was greater in the `r sum(lesson3f$physio)` physiotherapy group patients (`r style_sigfig(meansd1 %>% pull(mean), digits = 3)` points, SD `r style_sigfig(meansd1 %>% pull(sd), digits = 3)`) than in the `r nrow(lesson3f) - sum(lesson3f$physio)` controls (`r style_sigfig(meansd2 %>% pull(mean), digits = 3)`, SD `r style_sigfig(meansd2 %>% pull(sd), digits = 3)`). Although by t-test the difference between groups (`r style_sigfig(abs(physio_test$estimate[[1]] - physio_test$estimate[[2]]))`) was not statistically significant (p=`r style_pvalue(physio_test$p.value)`), the 95% confidence interval (`r style_sigfig(physio_test$conf.int[[2]]*-1)`, `r style_sigfig(physio_test$conf.int[[1]]*-2, digits = 3)`) includes clinically relevant effects. This suggests that the trial may have been underpowered to detect meaningful differences between groups.

</div>

An alternative conclusion, which I think I actually prefer, would be to focus on the difference between groups of `r style_sigfig(abs(physio_test$estimate[[1]] - physio_test$estimate[[2]]))`, deciding whether this is clinically significant.

## Week 4

```{r loadpkgs4, echo = TRUE}

# Week 4: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 4: load data
lesson4a <- readRDS(here::here("Data", "Week 4", "lesson4a.rds"))
lesson4b <- readRDS(here::here("Data", "Week 4", "lesson4b.rds"))
lesson4c <- readRDS(here::here("Data", "Week 4", "lesson4c.rds"))
lesson4d <- readRDS(here::here("Data", "Week 4", "lesson4d.rds"))
lesson4e <- readRDS(here::here("Data", "Week 4", "lesson4e.rds"))

```

### lesson4a

**This is a dataset on fifteen patients recording whether they had problematic nausea or vomiting after chemotherapy (defined as grade 2 or higher for either nausea or vomiting) and whether they reported being prone to travel sickness. Does travel sickness predict chemotherapy nausea and vomiting?**

To have a quick look at the data, create a two-by-two table:

```{r week4a, warning = FALSE}

# Create formatted table of nausea/vomiting by car sickness history
tbl_summary(
  lesson4a %>% select(nv, cs),
  by = cs,
  type = list(nv = "categorical")
)

```

```{r week4b, warning = FALSE, include = FALSE, purl = FALSE}

tbl_nv <-
  tbl_summary(
    lesson4a %>% select(nv, cs),
    by = cs,
    type = list(nv = "categorical"),
    statistic = list(nv = "{p}%")
  )

```

This shows, for example, `r inline_text(tbl_nv, variable = "nv", level = "1", column = "1")` of those who get car sick reported problematic nausea compared to only `r inline_text(tbl_nv, variable = "nv", level = "1", column = "0")` of those who aren't prone to car sickness. To find out whether this is statistically significant (it certainly seems clinically significant), you can use the `chisq.test` or the `fisher.test` function. For the `chisq.test` function, remember to use the `correct = FALSE` option to get the p-value without continuity correction.

```{r week4c, warning = FALSE}

# Chi squared test
chisq.test(table(lesson4a$nv, lesson4a$cs), correct = FALSE)

# Fisher's exact test
fisher.test(table(lesson4a$nv, lesson4a$cs))

```

`chisq.test` gives the p-value from a chi-squared test, `fisher.test` is a special form of this test when any of the numbers in the table are small, say 10 or below in any cell. The p-value is about 0.6. You now have 3 options:

1. Declare the result non-statistically significant, and conclude that you have failed to reject the null hypothesis of no difference between groups.
2.	Say that, though differences between groups were not statistically significant, sample size was too small.
3.	Say that differences between groups were not statistically significant, and that the study was too small, but try to quantify a plausible range of possible differences between groups.

For point 3, you need the confidence interval. You get this by using the `epi.2by2` command. Remember that if you want to compare the "exposed" to the "non-exposed" group, you will need to use the `factor` function and reverse the sort order for the two variables.

```{r week4d, warning = FALSE}

# Confidence interval for difference between groups
epi.2by2(
  table(
    factor(lesson4a$cs, levels = c(1, 0)),
    factor(lesson4a$nv, levels = c(1, 0))
  )
)

```

```{r week4e, include = FALSE, warning = FALSE, purl = FALSE}

tbl_cs <-
  epi.2by2(
  table(
    factor(lesson4a$cs, levels = c(1, 0)),
    factor(lesson4a$nv, levels = c(1, 0))
  )
)

tbl_cs_raw <- tbl_cs$massoc.summary %>% tibble()

exact_cs <- fisher.test(table(lesson4a$nv, lesson4a$cs))

```

This gives a "risk ratio" (same as relative risk) of `r style_ratio(tbl_cs_raw$est[tbl_cs_raw$var == "Inc risk ratio"])` with a 95% CI `r style_ratio(tbl_cs_raw$lower[tbl_cs_raw$var == "Inc risk ratio"])`, `r style_ratio(tbl_cs_raw$upper[tbl_cs_raw$var == "Inc risk ratio"])`. A model answer might be:

<div class="quote-container">

>`r str_to_title(xfun::numbers_to_words(as.numeric(tbl_cs$tab[1, 1])))` of the `r xfun::numbers_to_words(as.numeric(tbl_cs$tab[1, 3]))` patients (`r style_sigfig(as.numeric(tbl_cs$tab[1, 4]))`%) who reported prior car sickness had grade 2 or higher nausea and vomiting compared to `r xfun::numbers_to_words(as.numeric(tbl_cs$tab[2, 1]))` of the `r xfun::numbers_to_words(as.numeric(tbl_cs$tab[2, 3]))` (`r style_sigfig(as.numeric(tbl_cs$tab[2, 4]))`%) who reported no prior car sickness. Though differences between groups were not statistically significant (p=`r style_pvalue(exact_cs$p.value)` by Fisher's exact test), the sample size was small and the 95% confidence interval for the difference between groups includes differences of clinical relevance (relative risk `r style_ratio(tbl_cs_raw$est[tbl_cs_raw$var == "Inc risk ratio"])`; 95% CI `r style_ratio(tbl_cs_raw$lower[tbl_cs_raw$var == "Inc risk ratio"])`, `r style_ratio(tbl_cs_raw$upper[tbl_cs_raw$var == "Inc risk ratio"])`). It may be, for example, that problematic nausea and vomiting is up to six times more common in patients reporting prior car sickness than in those who do not.

</div>

### lesson4b

**An epidemiological study of meat consumption and hypertension. Meat consumption was defined as low, medium or high depending on whether subjects ate less than 3, 3 to 7 or 7 + meals with meat per week. Does meat consumption lead to hypertension?**

```{r week4f, include = FALSE, warning = FALSE, purl = FALSE}

tbl_meatrow <-
  tbl_summary(
    lesson4b %>% select(meat, hbp),
    by = hbp,
    statistic = list(meat = "{p}%"),
    percent = "row"
  )

tbl_meatcol <-
  tbl_summary(
    lesson4b %>% select(meat, hbp),
    by = hbp,
    statistic = list(meat = "{p}%"),
    percent = "col"
  )

```

There are three levels of meat consumption. The outcome (hypertension) is binary, either 1 or 0. So we will have a 3 by 2 table. Let’s start with a quick look:

```{r week4g, warning = FALSE}

# Formatted table of meat consumption by hypertension status
tbl_summary(
  lesson4b %>% select(meat, hbp),
  by = hbp
)

```

This would tell you, for example, that of the patients with hypertension, `r inline_text(tbl_meatcol, variable = "meat", level = "3", column = "1")` ate a lot of meat and only `r inline_text(tbl_meatcol, variable = "meat", level = "1", column = "1")` ate a little. I find this a less helpful statistic than presenting the data in terms of rates of hypertension for level of meat consumption. One other thing to notice is that the rates of hypertension are high, suggesting this is a selected population.

You also could have created this table:

```{r week4h, warning = FALSE}

# Formatted table of meat consumption by hypertension status (row percents)
tbl_summary(
  lesson4b %>% select(meat, hbp),
  by = hbp,
  percent = "row"
)

```

These tables show the number and percentages of patients with hypertension in each category of meat eating. Rates of hypertension are `r inline_text(tbl_meatrow, variable = "meat", level = "1", column = "1")`, `r inline_text(tbl_meatrow, variable = "meat", level = "2", column = "1")` and `r inline_text(tbl_meatrow, variable = "meat", level = "3", column = "1")` in the low, medium and high meat consumption groups, respectively.

To assess statistical significance, use the `chisq.test` function with the hypertension by meat consumption table as the input.

```{r week4i, warning = FALSE}

# Chi squared test for association between meat consumption and hypertension
chisq.test(table(lesson4b$hbp, lesson4b$meat), correct = FALSE)

```

The p-value is p=`r style_pvalue(chisq.test(table(lesson4b$hbp, lesson4b$meat), correct = FALSE)$p.value)`. How to interpret this? The formal statistical interpretation is that we can reject the null hypothesis that rates of hypertension are the same in each group. To demonstrate this, try renumbering the labels for the variable meat:

```{r week4j, warning = FALSE}

# Change values of meat consumption variable
lesson4b_changed <-
  lesson4b %>%
  mutate(
    meat =
      case_when(
        meat == 3 ~ 0.98573,
        meat == 2 ~ 60,
        meat == 1 ~ 643
      )
  )

# Re-run chi squared test
chisq.test(table(lesson4b_changed$hbp, lesson4b_changed$meat), correct = FALSE)

```

You get exactly the same result. This demonstrates that: a) the numbers you use for meat consumption act only as labels; b) the order is unimportant: you get the same p-value if you arrange the columns "low med hi" as "hi low med".

So it might be useful to do what are called "pairwise" comparisons: what difference is there in the rate of hypertension between low and medium meat eaters? What about high and low? Though there are three possible comparisons (hi v. lo; hi v. med; med v. lo), it is more usual to chose either the highest or lowest category and compare everything to that. The way to do these analyses is to create new variables. The code is given below (the #s are comments that are ignored by R).

```{r week4k, warning = FALSE}

# Create a new variable "c1" which is "1" if meat consumption is high and "0" if it is medium
# "c1" is missing for low meat consumption: these patients are left out of the analysis
lesson4b <-
  lesson4b %>%
  mutate(
    c1 =
      case_when(
        meat == 2 ~ 0,
        meat == 3 ~ 1
      )
  )

# Test for difference between medium and high meat consumption
epi.2by2(
  table(
    factor(lesson4b$c1, levels = c(1, 0)),
    factor(lesson4b$hbp, levels = c(1, 0))
  )
)

```

```{r week4l, warning = FALSE, include = FALSE, purl = FALSE}

# Overall chi-squared p-value
meat_chi <- chisq.test(table(lesson4b$meat, lesson4b$hbp), correct = FALSE)

# High vs medium
tbl_himed <- 
  epi.2by2(
    table(
      factor(lesson4b$c1, levels = c(1, 0)),
      factor(lesson4b$hbp, levels = c(1, 0))
    )
  )

tbl_himed_raw <- tbl_himed$massoc.summary %>% tibble()

```

```{r week4m, warning = FALSE}

# Compare high vs low consumption
# "c2" is "1" if meat consumption is high and "0" if it is low
# "c2" is missing for medium meat consumption: these patients are left out of the analysis
lesson4b <-
  lesson4b %>%
  mutate(
    c2 =
      case_when(
        meat == 1 ~ 0,
        meat == 3 ~ 1
      )
  )

# Test for difference between low and high meat consumption
epi.2by2(
  table(
    factor(lesson4b$c2, levels = c(1, 0)),
    factor(lesson4b$hbp, levels = c(1, 0))
  )
)

```

```{r week4n, warning = FALSE, include = FALSE, purl = FALSE}

tbl_hilo <- 
  epi.2by2(
    table(
      factor(lesson4b$c2, levels = c(1, 0)),
      factor(lesson4b$hbp, levels = c(1, 0))
    )
  )

tbl_hilo_raw <- tbl_hilo$massoc.summary %>% tibble()

# Compare low and medium for results
lesson4b <-
  lesson4b %>%
  mutate(
    c3 =
      case_when(
        meat == 1 ~ 0,
        meat == 2 ~ 1
      )
  )

tbl_medlo <- 
  epi.2by2(
    table(
      factor(lesson4b$c3, levels = c(1, 0)),
      factor(lesson4b$hbp, levels = c(1, 0))
    )
  )

tbl_medlo_raw <- tbl_medlo$massoc.summary %>% tibble()

```

What these commands do is to create new variables (c1 and c2) that are used instead of the variable "meat" in analyses. These are set to 1 or 0 or missing depending on the pairwise comparison that you want to do. A model answer might be as follows: 

<div class="quote-container">

>The results of the study are shown in the table. Differences in rates of hypertension between categories of meat consumption are statistically significant (p=`r style_pvalue(meat_chi$p.value)`). Rates of hypertension rise with increasing meat consumption: patients with the highest meat consumption had a risk of hypertension `r style_sigfig(tbl_himed_raw$est[tbl_himed_raw$var == "Inc risk ratio"])` times greater than those with intermediate meat consumption (95% CI `r style_sigfig(tbl_himed_raw$lower[tbl_himed_raw$var == "Inc risk ratio"])`, `r style_sigfig(tbl_himed_raw$upper[tbl_himed_raw$var == "Inc risk ratio"])`, p=`r style_pvalue(tbl_himed$massoc.detail$chi2.strata.uncor$p.value.2s)`) and `r style_sigfig(tbl_hilo_raw$est[tbl_hilo_raw$var == "Inc risk ratio"])` times greater than those with the lowest levels of meat consumption (95% CI `r style_sigfig(tbl_hilo_raw$lower[tbl_hilo_raw$var == "Inc risk ratio"])`, `r style_sigfig(tbl_hilo_raw$upper[tbl_hilo_raw$var == "Inc risk ratio"])`, p=`r style_pvalue(tbl_hilo$massoc.detail$chi2.strata.uncor$p.value.2s)`). Rates of hypertension were similar between medium and low meat consumption (relative risk `r style_sigfig(tbl_medlo_raw$est[tbl_medlo_raw$var == "Inc risk ratio"])`; 95% CI `r style_sigfig(tbl_medlo_raw$lower[tbl_medlo_raw$var == "Inc risk ratio"])`, `r style_sigfig(tbl_medlo_raw$upper[tbl_medlo_raw$var == "Inc risk ratio"])`, p=`r style_pvalue(tbl_medlo$massoc.detail$chi2.strata.uncor$p.value.2s)`).

</div>

```{r week4o, warning = FALSE, echo = FALSE, results = 'asis', purl = FALSE}

tbl_hbp <-
  lesson4b %>%
  mutate(
    meat_fac =
      as_factor(meat) %>%
      fct_recode("Low" = "1", "Medium" = "2", "High" = "3"),
    hbp_fac =
      as_factor(hbp) %>%
      fct_recode("No Hypertension" = "0", "Hypertension" = "1")
  ) %>%
  select(meat_fac, hbp_fac) %>%
  tbl_summary(
    by = hbp_fac,
    label = list(meat_fac = "Meat Consumption"),
    percent = "row"
  )

tbl_hbp %>%
  add_overall(last = TRUE)

```

You might note that I chose to compare low and medium meat consumption, that is, give all three pairwise comparisons rather than just high v. low and high v. medium. This is probably the exception rather than the rule: in this particular case, it seems worth reporting because the low and medium groups seem very comparable compared to high meat consumption.  

And now, the key point...

You may have noticed that my model answer did not actually answer the question. The question was "does meat consumption lead to hypertension?". I only answered in terms of rates of hypertension rising with increased meat consumption and the like. This is because you cannot use statistics to prove causality without thinking about the research design. If you go out and ask how much meat people eat and then measure their blood pressure, you cannot assume that any associations are causal. It may be, for example, that meat eaters tend to smoke more and it is smoking, not meat, that causes hypertension.

### lesson4c

**This is a dataset from a chemotherapy study. The researchers think that a mutation of a certain gene may be associated with chemotherapy toxicity. Should clinicians test for the gene during pre-chemotherapy work up?**

It is immediately obvious from this table that there are very few patients who are homozygous mutant type.

```{r week4p, warning = FALSE}

# Formatted two-way table of genes by toxicity outcome
tbl_summary(
  lesson4c %>% select(gene, toxicity),
  by = toxicity
)

```

It would seem appropriate to combine heterozygotes and homozygous mutant type into a single category. You might be tempted to type `lesson4c %>% mutate(gene = if_else(gene == 2, 1, gene))`. But you should avoid changing raw data in this way: it would be preferable to create a new variable as follows:

```{r week4q, warning = FALSE}

# Create binary variable grouping the values of "1" and "2" for gene
lesson4c <-
  lesson4c %>%
  mutate(
    mutant =
      case_when(
        gene == 1 | gene == 2 ~ 1,
        gene == 0 ~ 0
      )
  )

```

Moreover, it would be worth reporting the results of an analysis using all three groups, to investigate whether the conclusions change. This is sometimes called a "sensitivity analysis".

```{r week4r, warning = FALSE, include = FALSE, purl = FALSE}

tbl_gene <-
  tbl_summary(lesson4c %>% select(gene))

tbl_mutant <-
  tbl_summary(
    lesson4c %>% select(mutant, toxicity),
    by = toxicity,
    type = list(mutant = "categorical"),
    statistic = list(mutant = "{p}%")
  )

tbl_mutant_epi <- 
  epi.2by2(
    table(
      factor(lesson4c$mutant, levels = c(1, 0)),
      factor(lesson4c$toxicity, levels = c(1, 0))
    )
  )

tbl_mutant_epi_raw <- tbl_mutant_epi$massoc.summary %>% tibble()

p_gene_fisher <- fisher.test(table(lesson4c$gene, lesson4c$toxicity))$p.value

```

The results of the study are shown in the table. Very few participants (`r tbl_gene$table_body$stat_0[[4]]`) were homozygous mutant. For the purposes of analysis therefore, data for these participants was combined with those heterozygous for the gene. Patients with any mutant allele (i.e. heterozygous or homozygous mutant) had lower rates of toxicity (`r inline_text(tbl_mutant, variable = "mutant", level = "1", column = "1")` vs `r inline_text(tbl_mutant, variable = "mutant", level = "0", column = "1")`, p=`r style_pvalue(tbl_mutant_epi$massoc.detail$chi2.strata.uncor$p.value.2s)` by chi squared). The relative risk of toxicity is `r style_sigfig(tbl_mutant_epi_raw$est[tbl_mutant_epi_raw$var == "Inc risk ratio"])` compared to patients with the wild-type (95% CI `r style_ratio(tbl_mutant_epi_raw$lower[tbl_mutant_epi_raw$var == "Inc risk ratio"])`, `r style_ratio(tbl_mutant_epi_raw$upper[tbl_mutant_epi_raw$var == "Inc risk ratio"])`). This conclusion is not sensitive to the method of analysis: analysis of the table keeping participants in three groups gives p=`r style_pvalue(p_gene_fisher)` by an exact test. These findings should be confirmed in a larger series. In particular, it would be interesting to know whether patients who are homozygous mutant are at particularly increased risk.

```{r week4s, warning = FALSE, echo = FALSE, results = 'asis', purl = FALSE}

tbl_gene_toxic <-
  lesson4c %>%
  mutate(
    gene_fac =
      as_factor(gene) %>%
      fct_recode("Homozygous wild type" = "0", "Heterozygous" = "1",
                 "Homozygous mutant" = "2"),
    toxicity_fac =
      as_factor(toxicity) %>%
      fct_recode("No Grade III/IV Toxicity" = "0",
                 "Grade III/IV Toxicity" = "1")
  ) %>%
  select(gene_fac, toxicity_fac) %>%
  tbl_summary(
    by = toxicity_fac,
    label = list(gene_fac = "Gene"),
    percent = "row"
  )

tbl_gene_toxic %>%
  add_overall(last = TRUE)

```

Genetics type people: note that this gene is in Hardy Weinberg equilibrium!

One thing to note is my conclusion, the answer to the question. It would be a little premature to start changing clinical practice on the basis of a single study with a moderate number of patients and a less than overwhelming strength of evidence. Also, it is questionable whether you should start using a test just because it is predictive: you should use a test if it improves clinical outcome.

### lesson4d

**Patients are given chemotherapy regimen a or b and assessed for tumor response. Which regimen would you recommend to a patient? Do the treatments work differently depending on age or sex?**

The first thing we want to do is compare response by group. But using `epi.2by2` with "response" and "chemo" doesn't work. This is because the exposure variable has to be numeric (for example, 0 and 1), not "a" or "b". So you need to use the "group" variable instead of the "chemo" variable.

```{r week4t, include = FALSE, warning = FALSE, purl = FALSE}

tbl_chemoresponse <-
  tbl_summary(
    lesson4d %>% select(group, response),
    by = group,
    type = list(response = "categorical"),
    statistic = list(response = "{p}%")
 )

tbl_chemoresponse_epi <- 
  epi.2by2(
    table(
      factor(lesson4d$group, levels = c(1, 0)),
      factor(lesson4d$response, levels = c(1, 0))
    )
  )

tbl_chemoresponse_epi_raw <- tbl_chemoresponse_epi$massoc.summary %>% tibble()

median_age <-
  style_sigfig(quantile(lesson4d$age, c(0.5), na.rm = TRUE)[[1]])

```

This gives response rates of `r inline_text(tbl_chemoresponse, variable = "response", level = "1", column = "0")` on regimen "a" and `r inline_text(tbl_chemoresponse, variable = "response", level = "1", column = "1")` on regimen "b", a relative risk of `r style_sigfig(tbl_chemoresponse_epi_raw$est[tbl_chemoresponse_epi_raw$var == "Inc risk ratio"])` and a p-value of `r style_pvalue(tbl_chemoresponse_epi$massoc.detail$chi2.strata.uncor$p.value.2s)`. Should we conclude that there is no difference between groups and that you should feel free to use either regimen? Imagine you are a patient. You are told that you have a 50:50 chance of response on one regimen but only a 40% chance on the other. Unless there are good reasons to choose between the regimes (e.g. toxicity), which would you choose? The point here is that statistical significance does not really inform choices between similar alternatives. Assuming that toxicity, cost and inconvenience are similar between the regimes, I would recommend regimen a, even though the difference is not statistically significant. The confidence interval here is absolutely critical: the 95% C.I. for the risk difference is `r style_sigfig( tbl_chemoresponse_epi_raw$lower[tbl_chemoresponse_epi_raw$var == "Inc risk ratio"])`%, `r style_sigfig(tbl_chemoresponse_epi_raw$upper[tbl_chemoresponse_epi_raw$var == "Inc risk ratio"])`%. In other words, the response rate could be `r style_sigfig(abs(tbl_chemoresponse_epi_raw$lower[tbl_chemoresponse_epi_raw$var == "Inc risk ratio"]))`% higher on regimen a (e.g. 55% vs. `r style_sigfig(55 + tbl_chemoresponse_epi_raw$lower[tbl_chemoresponse_epi_raw$var == "Inc risk ratio"])`%) or 2% lower (e.g. 50% vs. `r style_sigfig(50 + tbl_chemoresponse_epi_raw$upper[tbl_chemoresponse_epi_raw$var == "Inc risk ratio"])`%). So you might do a lot better with regimen a, you are unlikely to do much worse. 

**The sub-group analyses**

A common mistake would be to use `epi.2by2` with "response" and "sex". However, this would examine whether, regardless of chemotherapy regimen used, men and women had different tumor outcome. What we want to see if the difference between treatment a and b changes depending on whether male or female patients are being treated.

To do this analysis, we first need to split the dataset up into two groups, one dataset including only men and the other including only women. You can use the `filter` function that you've previously seen to separate out males and females into different data sets. Here, sex is categorized as 0 for male and 1 for female.

```{r week4u}

# Use "filter" to select only male patients
lesson4d_males <-
  lesson4d %>%
  filter(sex == 0)

# To confirm:
table(lesson4d_males$sex)

# Use "filter" to select only female patients
lesson4d_females <-
  lesson4d %>%
  filter(sex == 1)

# To confirm:
table(lesson4d_females$sex)

# Males (sex == 0)
epi.2by2(
  table(
    factor(lesson4d_males$group, levels = c(1, 0)),
    factor(lesson4d_males$response, levels = c(1, 0))
  )
)

# Females (sex == 1)
epi.2by2(
  table(
    factor(lesson4d_females$group, levels = c(1, 0)),
    factor(lesson4d_females$response, levels = c(1, 0))
  )
)
```

What you get is a statistically significant difference between treatment groups for men (many more respond on regimen a) but not women (actually a few more respond on regimen b). How to interpret this? In the literature, this might well be trumpeted as showing that though either regimen could be used for women, regimen a is better for men. My own view is that sub-group analyses are hypothesis generating not hypothesis testing. In particular, is there any reason to believe that response to chemotherapy might depend on sex? I don't think there are any cases of this. 

Testing age is a little more difficult as it is a continuous variable. One typical approach might be to create two sub-groups depending on the median. First, `quantile(lesson4d$age, c(0.5), na.rm = TRUE)` gives a median age of `r median_age`. So:

```{r week4v}

# Use "filter" again to select age
lesson4d_younger <-
  lesson4d %>%
  filter(age <= 42)

lesson4d_older <-
  lesson4d %>%
  filter(age > 42)

# Younger patients 
epi.2by2(
  table(
    factor(lesson4d_younger$group, levels = c(1, 0)),
    factor(lesson4d_younger$response, levels = c(1, 0))
  )
)

# Older patients
epi.2by2(
  table(
    factor(lesson4d_older$group, levels = c(1, 0)),
    factor(lesson4d_older$response, levels = c(1, 0))
  )
)
```

You get no difference between groups for either older or younger patients. As it turns out, this is not a very efficient method of testing for age differences. A better technique will be discussed in the class on regression.

**Interaction or sub-group analysis?**

There is a further problem here: we have one question ("do effects differ between men and women?") and two p-values (one for men and one for women). What you really want is one p-value to answer one question. The correct statistical technique for looking at whether the effects of treatment differ between sub-groups is called interaction. We will look at this later in the course. In the meantime, if you are interested, you can read some brief articles at: 

[Statistics Notes: Interaction 1: heterogeneity of effects](http://bmj.bmjjournals.com/cgi/content/full/313/7055/486?ijkey=f0d0304067151ab3c6490b209ca3e954acb60a29&keytype2=tf_ipsecsha)

[Statistics Notes: Interaction 2: compare effect sizes not p-values](http://bmj.bmjjournals.com/cgi/content/full/313/7060/808?ijkey=7172a78ea07bf92702ec4a33c6804b3ea439c46c&keytype2=tf_ipsecsha)

[Statistics Notes: Interaction 3: How to examine heterogeneity](http://bmj.bmjjournals.com/cgi/content/full/313/7061/862?ijkey=c1181f258aa1146139604ac7d463ec93caa4d623&keytype2=tf_ipsecsha)

### lesson4e

**This is a lab study of two candidate tumor-suppressor genes (gene1 and gene2). Wild-type mice are compared with mice that have gene1 knocked-out, gene2 knocked-out or both. The presence of tumors is measured after 30 days. Do the genes suppress cancer?**

The obvious thing to do would be to use `epi.2by2` with "cancer" and "gene1", and then with "cancer" and "gene2". Superficially this would suggest that gene1 is a tumor suppressor gene and gene2 is not. However, don't get too fixated on p-values. The proportion of cancer in mice with gene2 knocked out is over twice that of controls. Remember that animal experiments tend to use a very small number of observations (a typical clinical trial has hundreds of patients, a typical lab study has maybe a dozen mice). So you might want to say that there is good evidence that gene1 is a tumor suppressor gene but that whilst evidence is suggestive for gene2, more research is needed.

A BIG HOWEVER - have a look at the data or this table:

```{r week4w, warning = FALSE}

# Formatted table of gene1 by gene2
tbl_summary(
  lesson4e %>% select(gene1, gene2),
  by = gene2,
  type = list(gene1 = "categorical")
)

```

```{r week4x, warning = FALSE, include = FALSE, purl = FALSE}

lesson4e_gene0 <- lesson4e %>% filter(gene2 == 0)
lesson4e_gene1 <- lesson4e %>% filter(gene2 == 1)

# gene2 == 0
tbl_gene0 <-
  epi.2by2(
    table(
      factor(lesson4e_gene0$gene1, levels = c(1, 0)),
      factor(lesson4e_gene0$cancer, levels = c(1, 0))
    )
  )

# gene2 == 1
tbl_gene1 <-
  epi.2by2(
    table(
      factor(lesson4e_gene1$gene1, levels = c(1, 0)),
      factor(lesson4e_gene1$cancer, levels = c(1, 0))
    )
  )

```

The experimental design was to knockout no genes in some animals, gene1 in some animals, gene2 in other animals and both genes in a final set of animals. This is known as a factorial or Latin-square design. Analyzing rates of cancer for mice without gene1 or gene2, as suggested above, ignores this experimental design. Presumably the design was implemented because the researchers wanted to know if the effects of gene1 differed depending on whether gene2 had been knocked-out and vice versa. Now you could start doing separate sub-groups (e.g. using `epi.2by2` for "cancer" and "gene1", filtering by "gene2==0" and "gene2==1" separately) but this produces somewhat unhelpful results. For example, it suggests that gene1 has an effect for wild-type gene2 (p=`r style_pvalue(tbl_gene0$massoc.detail$chi2.strata.uncor$p.value.2s)`) but maybe not for knocked out gene2 (p=`r style_pvalue(tbl_gene1$massoc.detail$chi2.strata.uncor$p.value.2s)`). This has all the look and feel of a spurious sub-group analysis, however. We will discuss some regression approaches to this problem later in the lecture series.

## Week 5

```{r loadpkgs5, echo = TRUE}

# Week 5: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 5: load data
lesson5a <- readRDS(here::here("Data", "Week 5", "lesson5a.rds"))
lesson5b <- readRDS(here::here("Data", "Week 5", "lesson5b.rds"))
lesson5c <- readRDS(here::here("Data", "Week 5", "lesson5c.rds"))
lesson5d <- readRDS(here::here("Data", "Week 5", "lesson5d.rds"))
lesson5e <- readRDS(here::here("Data", "Week 5", "lesson5e.rds"))
lesson5f <- readRDS(here::here("Data", "Week 5", "lesson5f.rds"))
lesson5g <- readRDS(here::here("Data", "Week 5", "lesson5g.rds"))
lesson5h <- readRDS(here::here("Data", "Week 5", "lesson5h.rds"))
lesson5i <- readRDS(here::here("Data", "Week 5", "lesson5i.rds"))

```

### lesson5a

**These are data from marathon runners (again). Which of the following is associated with how fast runners complete the marathon: age, sex, training miles, weight?**

My guess here is that we are going to want to do a regression analysis. This would allow us to quantify the association between the various predictor variables and race time. For example, it would be interesting to know not only that number of weekly training miles is correlated with race time, but by how much you can reduce your race time if you increased your training by a certain amount. Our dependent variable is "rt" (race time in minutes), so we could type:

```{r week5a}

# Create linear regression model for race time
rt_model <- lm(rt ~ age + sex + tr + wt, data = lesson5a)

# Results of linear regression model
summary(rt_model)

```

```{r week5b, echo = FALSE, warning = FALSE, purl = FALSE}

rt_N <- nrow(lesson5a)

rt_Nfull <- nobs(rt_model)

rt_tbl1 <-
  lesson5a %>%
  filter(!is.na(wt) & !is.na(age) & !is.na(rt)) %>%
  tbl_summary(
    label =
      list(age = "Age (years)", sex = "Female",
           tr = "Training miles per week",
           wt = "Weight (kg)",
           rt = "Race time (minutes)"),
    statistic = list(all_continuous() ~ "{mean} ({sd})")
  )

rt_tbl2 <-
  rt_model %>%
  tbl_regression(
    label = list(age = "Age (years)", sex = "Female",
                 tr = "Training miles per week",
                 wt = "Weight (kg)")
  )

male_avg <-
  lesson5a %>%
  filter(sex == 0) %>%
  summarize(mean = mean(rt, na.rm = TRUE)) %>%
  pull(1)

```

The p-values for all the predictor variables apart from weight are very low. A model answer might be:

<div class="quote-container">

>There were `r rt_N` runners in the dataset; full data were available for `r rt_Nfull`. Summary data for these `r rt_Nfull` are given in table 1. Predictors of race time are shown in table 2. Age, sex and number of training miles were all statistically significant predictors of race time; weight is unlikely to have an important effect.

</div>

<center> **Table 1** </center>

```{r week5c, echo = FALSE, results = "asis", purl = FALSE}

rt_tbl1

```

<center> **Table 2** </center>

```{r week5d, echo = FALSE, results = "asis", purl = FALSE}

rt_tbl2

```

A real-life decision you could take away from this is that every additional mile you run in training would be predicted to cut about 1.5 minutes from your marathon time: add a couple of extra five mile runs per week and you’ll shave a quarter of an hour off your time. 

A couple of thoughts. First, you will note that I didn’t remove weight from the model (that is, use a step wise approach) then report the coefficients and p-values for the new model (by typing `lm(rt ~ age + sex + tr, data = lesson5a)`).

Second, race time is not normally distributed and the textbooks would have us believe that this invalidates a regression analysis. Let’s try:

```{r week5e}

# Create variable for log of race time
lesson5a <-
  lesson5a %>%
  mutate(
    lt = log(rt)
  )

# Create linear regression model for log of race time
rtlog_model <- lm(lt ~ age + sex + tr + wt, data = lesson5a)

# Results of linear regression model
summary(rtlog_model)

```

This creates a new variable called "lt" that is the log of race time. You can use the `skim` function to see that it is normally distributed. Now let’s look at the results of the regression analysis: the p-values are almost exactly the same. This suggests that the non-normality of race time is not important in this setting.

_For advanced students only_

It might be interesting to compare the coefficients from the untransformed and log transformed models. For example, women are predicted to run about `r inline_text(rt_tbl2, variable = "sex", pattern = "{estimate}")` minutes slower on the untransformed model; the coefficient in the log model is `r style_sigfig(rtlog_model$coefficients[[3]], digits = 3)`. Backtransform by typing ``exp(`r style_sigfig(rtlog_model$coefficients[[3]], digits = 3)`)`` and you get `r style_sigfig(exp(rtlog_model$coefficients[[3]]), digits = 3)`. Remember that backtransforming gives you a proportion. So to work out the difference between men and women in race time, first work out the average men’s time:

```{r week5f}

# Get the average time for men
lesson5a %>%
  filter(sex == 0) %>% # Select only males
  skim(rt)

```

Then multiply the men's average (`r style_sigfig(male_avg, digits = 4)`) by `r style_sigfig(exp(rtlog_model$coefficients[[3]]), digits = 3)` to get the women's time, which gives `r style_sigfig(male_avg*exp(rtlog_model$coefficients[[3]]), digits = 4)`.

Subtract one from the other to get `r style_sigfig(male_avg*exp(rtlog_model$coefficients[[3]]) - male_avg, digits = 3)` minutes difference in race time between the sexes. This is very close to the value from the untransformed model.

### lesson5b

**These are data on patients with a disease that predisposes them to cancer. The disease causes precancerous lesions that can be surgically removed. A group of recently removed lesions are analyzed for a specific mutation. Does how long a patient has had the disease affect the chance that a new lesion will have a mutation?**

What you are trying to predict here is binary (mutation / no mutation). You are predicting with a continuous variable (length of disease). So a logistic regression would work nicely. Try:

```{r week5g, results = "asis"}

# Create logistic regression model
mutate_model <- glm(mutation ~ c, data = lesson5b, family = "binomial")

# Formatted results with odds ratios
tbl_regression(mutate_model, exponentiate = TRUE)

```

If you get a p-value of around 0.7, you haven't been inspecting your data. One patient has apparently had the disease for 154 years. Either this is a freak of nature or the study assistant meant to type 14 or 15. You need to delete this observation from the dataset and try the model again:

```{r week5h, results = "asis"}

# Use "filter" to exclude patients with outlying disease duration
lesson5b <-
  lesson5b %>%
  filter(c <= 50)

# Create logistic regression model
mutate_model <- glm(mutation ~ c, data = lesson5b, family = "binomial")

# Formatted results with odds ratios
tbl_regression(mutate_model, exponentiate = TRUE)

```

```{r week5i, results = "asis"}

# Formatted results in logits
tbl_regression(mutate_model, exponentiate = FALSE)

```

```{r week5j, echo = FALSE, purl = FALSE}

mutate_or <-
  mutate_model %>%
  tbl_regression(exponentiate = TRUE)

mutate_logit <-
  mutate_model %>%
  tbl_regression(intercept = TRUE,
                 exponentiate = FALSE)

log_calc10 <-
  mutate_logit$table_body$estimate[2]*10 +
  mutate_logit$table_body$estimate[1]

log_exp10 <-
  exp(log_calc10)/(1 + exp(log_calc10))*100

log_calc3 <-
  mutate_logit$table_body$estimate[2]*3 +
  mutate_logit$table_body$estimate[1]

log_exp3 <-
  exp(log_calc3)/(1 + exp(log_calc3))*100

```

After fixing the data, you will now find an association (`r inline_text(mutate_or, variable = "c", pattern = "{p.value}")`). Using the `tbl_regression` function, you get an odds ratio of `r inline_text(mutate_or, variable = "c", pattern = "{estimate}")`, meaning that the odds of having a mutation increase by `r inline_text(mutate_or, variable = "c", pattern = "{estimate}")` each year.

You can get the constant or intercept term from the `tbl_regression` function by using the `intercept = TRUE` option, and the coefficients in logits using the `exponentiate = FALSE` option.

```{r week5k, results = "asis"}

# Results in logits
# The "intercept = TRUE" option includes the constant in the table
tbl_regression(mutate_model,
               exponentiate = FALSE,
               intercept = TRUE)

```

This gives a coefficient of `r inline_text(mutate_logit, variable = "c", pattern = "{estimate}")` and a constant of `r inline_text(mutate_logit, variable = "(Intercept)", pattern = "{estimate}")`. This can be used to make a specific prediction using the equation below ("l" stands for the log odds).

$p = e^l / (e^l+1)$

Take someone who has had the disease for 10 years. Their logit is 10 times the coefficient of `r inline_text(mutate_logit, variable = "c", pattern = "{estimate}")` minus the constant `r inline_text(mutate_logit, variable = "(Intercept)", pattern = "{estimate}")` to give `r style_sigfig(log_calc10)`. Plug `r style_sigfig(log_calc10)` into the equation (``exp(`r style_sigfig(log_calc10)`)/(exp(`r style_sigfig(log_calc10)`)+1)``) and you get `r style_sigfig(log_exp10)`%. Someone who has had the disease for 3 years has a logit of `r style_sigfig(log_calc3)` giving a risk (``exp(`r style_sigfig(log_calc3)`)/(exp(`r style_sigfig(log_calc3)`)+1)``) of `r style_sigfig(log_exp3)`%.

If you wanted to get flashy, you could work out the risk for each year between 2 and 18 and get a graph. But R can do this automatically for you: you can create a variable with the risk of mutation for each observation based on the duration of disease using the `augment` function. The column that contains the risk is called ".fitted". Since this is a logistic regression model, we also need to specify `type.predict = "response"` to get the predicted probabilities.

```{r week5l}

# Create predictions
lesson5b_pred <-
  augment(mutate_model,
          type.predict = "response")

# Show resulting dataset
lesson5b_pred

# Graph over disease duration
# Tells the plot what data to use, and what variables correspond
# to the x and y axes
ggplot(data = lesson5b_pred, aes(x = c, y = .fitted)) +
  # Creates the line portion of the graph
  geom_line() +
  # Creates the points along the line
  geom_point() +
  # Labels the x and y axes
  labs(
    x = "Disease duration",
    y = "Risk of mutation"
  )

```

You can also use the `augment` function for linear regression and multivariable models. One other interesting thing you can do is to make "out of sample" predictions.

Try this:

```{r week5m, results = "asis"}

# Reopen lesson5b dataset
lesson5b <- readRDS(here::here("Data", "Week 5", "lesson5b.rds"))

# Use original logistic regression model
tbl_regression(mutate_model, exponentiate = TRUE)

```

```{r week5n, results = "asis"}

# Create new values for "c" (disease duration)
lesson5b_new <-
  lesson5b %>%
  mutate(c = row_number()/3)
# "row_number()" gives the observation number for each observation
# Replace c with observation number / 3 gives a list of simulated
# disease durations between 0.33 and 42.33.

# Predict risk of mutation
# The "newdata" option allows you to get predictions for a dataset
# other than the dataset that was used to create the model
lesson5b_pred_new <-
  augment(mutate_model,
          newdata = lesson5b_new,
          type.predict = "response")

# Create graph
ggplot(data = lesson5b_pred_new,
       aes(x = c, y = .fitted)) +
  geom_line()

```

### lesson5c

**These are data from Canadian provinces giving population, unemployment rates and male and female life expectancy. Which of these variables are associated?**

A key first question: what are we likely to be interested in? For example, total population and unemployment rate will have no illuminating relationship whatsoever and we wouldn’t want to analyze the association between these two. The link between unemployment and life expectancy seems more interesting. Before we start doing the analysis however, we need to look at the data.

```{r week5o, eval = FALSE}

# Open up dataset to view observations
View(lesson5c)

```

It seems that there are not only data for each province separately but for Canada as a whole. Clearly we would have to delete this row as it is not an independent observation.

```{r week5p}

# Remove the observation for all of Canada from dataset
lesson5c_fixed <-
  lesson5c %>%
  filter(place != "Canada")

```

Now, we could just correlate the three variables together: 

```{r week5q}

# Calculate correlation between unemployment and male/female life expectancy
# There are missing values for unemployment,
# so we need to indicate that we only want to use "complete observations"
cor(lesson5c_fixed %>% select(unemp, mlife, flife),
    use = "complete.obs")

```

This tells you that unemployment rates are negatively correlated with life expectancy (i.e. the higher the unemployment rate, the lower the life expectancy), that this effect seems stronger for men than for women and that male and female life expectancy are strongly correlated.

We might also want to go on and do some regressions. We probably wouldn’t ever want to predict the unemployment rate on the basis of life expectancy, but the opposite case is indeed of interest: we might want to know, for example, what effect a 1% drop in unemployment rate might have on life expectancy. 

Try these regression models:

```{r week5r, results = "asis"}

# Create linear regression model for male life expectancy
mlife_model <- lm(mlife ~ unemp, data = lesson5c_fixed)
tbl_regression(mlife_model)

```

```{r week5s, results = "asis"}

# Create linear regression model for female life expectancy
flife_model <- lm(flife ~ unemp, data = lesson5c_fixed)
tbl_regression(flife_model)

```

The coefficients you get (`r inline_text(tbl_regression(mlife_model), variable = "unemp", pattern = "{estimate}")` for men and `r inline_text(tbl_regression(flife_model), variable = "unemp", pattern = "{estimate}")` for women) suggest that a 5% drop in unemployment is associated with about a 6 month increase in life expectancy, in other words, a small effect.

Interesting question: should you also report a p-value and 95% confidence interval for the coefficients? The answer is no. This is because Canadian provinces are not some random sample from a large theoretical population of Canadian provinces. You have all the data. So questions of inference (i.e. p-values) and uncertainty (i.e. 95% confidence intervals) don’t come into it.

Even more interesting question: the conclusion of a 5% drop in unemployment being associated with a 6 month increase in life expectancy is based on a causal relationship, that is, we believe that changes in unemployment _cause_ changes in life expectancy. This is not implausible: unemployment leads to poverty and depression, both of which reduce life expectancy. However, a causal relationship cannot be assumed. For example, it may be that life expectancy is lower in certain areas of the country (due to eating patterns or ethnic differences) that also happen to suffer higher unemployment. 

### lesson5d

**These are data from mice inoculated with tumor cells and then treated with different doses of a drug. The growth rate of each animal’s tumor is then calculated. Is this drug effective?**

This is a straightforward linear regression that shows a significant decrease in log tumor size with increasing dose.

```{r week5t}

# Create linear regression model for tumor size
tumorsize_model <- lm(s ~ dose, data = lesson5d)
summary(tumorsize_model)

```

A couple of thoughts. Firstly, this rather obvious analysis is not often conducted in lab research. Typically, researchers present pairwise comparisons between each dose and control. For example, see the following typical diagram. Each of the p-values compares the dose to control. The problem with such an approach is that you end up with multiple p-values (instead of just one) and that each test takes place in a vacuum: the p-value of a comparison between no treatment and, say, dose level 3, is the same regardless of whether there were 2 dose levels in the experiment, or 100, and whether all other dose levels showed an effect or did not. A regression analysis gives you a single p-value and uses all data in one analysis.

```{r week5u, echo = FALSE, results = "asis", fig.width = 4, fig.height = 4, purl = FALSE}

# Create dataset to create figure
df_graph <-
  tribble(
    ~x, ~y, ~p, ~sd,
    0, 100, "", 8,
    25, 110, "p=0.219", 10,
    50, 115, "p=0.0033", 15,
    100, 120, "p=0.0001", 12
  ) %>%
  mutate(x = factor(x))

ggexample <-
  ggplot(data = df_graph) +
  geom_bar(aes(x = x, y = y),
           stat = "identity",
           width = 0.5,
           fill = "gray80",
           color = "black",
           position = "dodge") +
  geom_errorbar(aes(ymin = y, ymax = y + sd, x = x),
                width = 0.2) +
  geom_text(aes(x = x, y = y, label = p),
            position = position_dodge(width = 0.9),
            vjust = -4.25) +
  scale_y_continuous(limits = c(0, 140), breaks = seq(0, 140, by = 20)) +
  labs(
    x = "",
    y = "CFU (% of Control)"
  )

plot(ggexample)

```

A second thought: should you report the coefficient of `r tumorsize_model$coefficients[[2]] %>% style_sigfig(digits = 5)`? This can be interpreted as "for each increase in dose of one unit, increase in log tumor size is less by `r tumorsize_model$coefficients[[2]] %>% style_sigfig(digits = 5)`". I would argue that this coefficient might be misleading because you only have a few doses and they are widely spaced. Also, dose-response is often non-linear: it generally takes a sigmoidal curve (see below). In short, you might have too few data to be confident about a linear prediction. Finally, it is rare that you really want to estimate the effects of a treatment on a mouse: generally, laboratory studies are about testing hypotheses.

```{r week5v, echo = FALSE, results = "asis", fig.width = 4, fig.height = 4, purl = FALSE}

# Dose response curve

sigmoid = function(x) {
  1 / (1 + exp(-x))
}

df_graph2 <-
  tibble(
    x = seq(-5, 5, by = 0.1),
    y = sigmoid(x)
  )

ggexample2 <-
  ggplot(data = df_graph2,
         aes(x = x, y = y)) +
  geom_line() +
  labs(
    x = "Dose",
    y = "Response"
  ) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  theme_bw()

plot(ggexample2)

```

My model answer would be:

<div class="quote-container">

>Mean increase in log tumor size per day by dose is given in the table. Higher doses were associated with lower growth rates (`r inline_text(tbl_regression(tumorsize_model), variable = "dose", pattern = "{p.value}")` by linear regression).

</div>

```{r week5w, echo = FALSE, warning = FALSE, results = "asis", purl = FALSE}

df_tbl5d <-
  tbl_summary(
    lesson5d %>% select(dose, s),
    by = dose,
    statistic = list(all_continuous() ~ "{mean} ({sd})"))

df_tbl5dcol <-
  df_tbl5d$table_body %>%
  select(stat_1, stat_2, stat_3, stat_4) %>%
  pivot_longer(
    cols = c(stat_1, stat_2, stat_3, stat_4),
    names_to = "name",
    values_to = "value"
  ) %>%
  mutate(
    dose =
      case_when(
        name == "stat_1" ~ 0,
        name == "stat_2" ~ 4,
        name == "stat_3" ~ 40,
        name == "stat_4" ~ 400
      )
  ) %>%
  select(dose, value) %>%
  gt() %>%
  cols_label(dose = "Dose",
             value = "Mean (SD)")

df_tbl5dcol

```

### lesson5e

**These are data from a study of the use of complementary medicine (e.g. massage) by UK breast cancer patients. There are data for the women’s age, time since diagnosis, presence of distant metastases, use of complementary medicine before diagnosis, whether they received a qualification after high school, the age they left education, whether usual employment is a manual trade, socioeconomic status. What predicts use of complementary medicine by women with breast cancer?**

This is a fairly simple analysis: the outcome is binary and as we want to make predictions we are going to want a logistic regression. It would be tempting just to throw all the variables into the analysis:

```{r week5x}

# Create multivariable logistic regression model for CAM
cam_model1 <- glm(CAM ~ age + t + mets + u + q18 + e + m + ses,
                  data = lesson5e,
                  family = "binomial")
tbl_regression(cam_model1, exponentiate = TRUE)

```

This would suggest that the strongest predictor is whether women used complementary medicine before diagnosis and that two other variables are predictive: women with a qualification after leaving high school are more likely to use complementary medicine, but use declines with age (older people are more conservative, or alternatively, wiser, depending on your point of view.)

However...

Should we just throw everything in the model? For example, only 6 patients have distant metastases. Secondly, many of the variables seem highly correlated. For example, age at which the patient left education and whether they received a qualification after the age of 18 are highly correlated as are socioeconomic status and whether the patient’s job is a manual trade. In clinical terms, you wouldn’t need to know the age that someone left education if you already knew whether they had a post-high school qualification. And as would be intuitive, regression does not deal well with correlated variables. To take an extreme example, take two variables "x" which is equal to height, and "y" which is equal to height plus 1 inch. These have a correlation of one. Regressing just variable x or y on shoe size you get:

$shoesize = 0.6*x - 30$

or

$shoesize = 0.6*y - 31$

What would you get for regressing x and y? Any of the following are possible:

$shoesize = 0.3*x + 0.3*y - 30.5$

$shoesize = 0.4*x + 0.2*y - 30.5$

$shoesize = 0.1*x + 0.5*y - 30.5$

There is no way of telling these apart in terms of regression. Bottom line: care is needed with correlated variables both in a clinical  / scientific sense (you don’t need both of two correlated variables in a model) and a statistical sense (regression results can be misleading).

So I would start with the full model and then remove the least predictive of socioeconomic status and manual trade, and the least predictive of qualification and age left education. You end up with:

```{r week5y}

# Create logistic regression model for CAM removing "e" and "m"
cam_model2 <- glm(CAM ~ age + t + mets + u + q18 + ses,
                  data = lesson5e,
                  family = "binomial")
tbl_regression(cam_model2, exponentiate = TRUE)

```

Now it appears that "q18" is predictive but not "ses". So try removing one of these from the model in turn:

```{r week5z, results = "asis"}

# Create logistic regression model for CAM removing "q18"
cam_model3 <- glm(CAM ~ age + t + mets + u + ses,
                  data = lesson5e,
                  family = "binomial")
tbl_regression(cam_model3, exponentiate = TRUE)

```

```{r week51, results = "asis"}

# Create logistic regression model for CAM removing "ses"
cam_model4 <- glm(CAM ~ age + t + mets + u + q18,
                  data = lesson5e,
                  family = "binomial")
tbl_regression(cam_model4, exponentiate = TRUE)

```

It turns out that both are predictive independently, but not together. When you think about this, it is because socioeconomic status is correlated with education. The most sensible thing to do is to leave "q18" in the model as a) it is slightly more predictive and b) it is easier to ask about; c) there are fewer missing data. As such, my model answer might be:

<div class="quote-container">

>There were responses from `r nrow(lesson5e)` women, of whom `r length(cam_model4$fitted.values)` had data adequate for analysis. There were more missing data for socioeconomic status but this was not included in the final model. In a multivariable model, use of complementary medicine before diagnosis was the strongest predictor of complementary medicine use in women with breast cancer, odds ratio `r inline_text(tbl_regression(cam_model4, exponentiate = TRUE), variable = "u")`. Complementary medicine use was related to education. The odds of a woman with a qualification received after the age of 18 using complementary medicine were `r inline_text(tbl_regression(cam_model4, exponentiate = TRUE), variable = "q18")` those of women without a qualification after high school. In a univariate model, higher socioeconomic status predicted use of complementary medicine, but this was dropped from the multivariable model due to collinearity with educational achievement. Older women were less likely to use complementary medicine `r inline_text(tbl_regression(cam_model4, exponentiate = TRUE), variable = "age", pattern = "(odds ratio {estimate} for a one-year increase in age; {conf.level*100}% CI {conf.low}, {conf.high}, {p.value})")`. There was no statistically significant effect of time since diagnosis `r inline_text(tbl_regression(cam_model4, exponentiate = TRUE), variable = "t", pattern = "(odds ratio {estimate} per year; {conf.level*100}% CI {conf.low}, {conf.high}, {p.value})")`. This suggests that breast cancer patients who use complementary medicine are likely to start doing so shortly after diagnosis.

</div>

### lesson5f

**These are the distance records for Frisbee for various ages in males. What is the relationship between age and how far a man can throw a Frisbee?**

Well the obvious thing to do would be a linear regression:

```{r week52}

# Create linear regression model for distance
frisbee_model <- lm(distance ~ age, data = lesson5f)
summary(frisbee_model)

```

You get a coefficient of `r style_sigfig(frisbee_model$coefficients[[2]], digits = 3)`, meaning that the furthest a man can throw a Frisbee increases by `r style_sigfig(frisbee_model$coefficients[[2]], digits = 3)` meters every year. But of course this is nonsense: you can’t throw further and further each year, athletic ability starts to decline with age. You can see this on a graph:

```{r week53}

# Scatterplot of distance by age
ggplot(data = lesson5f,
       aes(x = age, y = distance)) + 
  geom_point()

```

In other words, there is not a linear relationship between your age and the distance you can throw a Frisbee. There are two options. You can either do two linear regressions, one for age up to 30 and one for age >30. But this is a little sloppy: better, you could try including non-linear terms (see below). In either case, remember not to report p-values or 95% confidence intervals: these are meaningless because there is only one record per distance.

_For advanced students only:_

Often the relationship between an $x$ and a $y$ does not follow a straight line. You may remember from high school that one way to get a curve is to have a quadratic equation including both $x$ and $x^2$. So you have to create a new variable called age2 using `mutate(age2 = age^2)` and regress:

```{r week54}

# Create new variable for age squared
lesson5f <-
  lesson5f %>%
  mutate(
    age2 = age^2
  )

# Create linear regression model using age and age squared
frisbee_model2 <- lm(distance ~ age + age2, data = lesson5f)
summary(frisbee_model2)

```

```{r week55, echo = FALSE, purl = FALSE}

agecoef <-
  style_sigfig(frisbee_model2$coefficients[[2]], digits = 3)

age2coef <-
  style_sigfig(frisbee_model2$coefficients[[3]], digits = 3)

```

This model (distance = 11.6\*age - 0.149\*age^2 + 8.13) fits extremely well (r^2^ of `r style_sigfig(summary(frisbee_model2)$r.squared)` vs `r style_sigfig(summary(frisbee_model)$r.squared)` for the linear model). If you really remember your high school math, consider that for a regression equation $y = ax + bx^2 + c$ you can work out the maximum $y$ as $-a/2b$. We predict that the world record for distance will be held by a man who is -`r agecoef`/(2 * `r age2coef`) = `r style_sigfig(-frisbee_model2$coefficients[[2]]/(2 * frisbee_model2$coefficients[[3]]), digits = 3)` years old.

Here is the predicted fit from the model using age and age^2^:

```{r week55a, echo = FALSE, purl = FALSE}

frisbee_model2_pred <-
  augment(frisbee_model2)

ggplot(data = frisbee_model2_pred) +
  geom_point(aes(x = age, y = distance)) +
  geom_smooth(aes(x = age, y = .fitted), col = "red")

```

Note: while adding a quadratic term (here, the squared term) fit this data well, statisticians do not often use quadratic terms to model non-linear associations. There are a number of other methods for creating models for a non-linear association, but these will not be covered in this course.

### lesson5g

**You’ve seen this dataset before. Patients with lung cancer are randomized to receive either chemotherapy regime a or b and assessed for tumor response. We know there is no difference between regimes (you can test this if you like).  However, do the treatments work differently depending on age or sex?**

The first thing to do here is to do the sub-group analysis, just to get a feel for the data. 

Try this:

```{r week56}

# For men
tbl_summary(
  lesson5g %>% filter(sex == 0) %>% select(response, chemo),
  by = chemo,
  type = list(response = "categorical")
)

# For women
tbl_summary(
  lesson5g %>% filter(sex == 1) %>% select(response, chemo),
  by = chemo,
  type = list(response = "categorical")
)

# Here, the "summarize" function stores out the p-values for the chi-squared test by sex
lesson5g %>%
  group_by(sex) %>%
  summarize(p = chisq.test(response, chemo, correct = FALSE)$p.value)

```

```{r week57, echo = FALSE, warning = FALSE, purl = FALSE}

chitable_men <-
  tbl_summary(
    lesson5g %>% filter(sex == 0) %>% select(response, chemo),
    by = chemo,
    type = list(response = "categorical"),
    statistic = list(response = "{p}%")
  )

chitable_women <-
  tbl_summary(
    lesson5g %>% filter(sex == 1) %>% select(response, chemo),
    by = chemo,
    type = list(response = "categorical"),
    statistic = list(response = "{p}%")
  )

chip1 <-
  lesson5g %>%
  group_by(sex) %>%
  summarize(p = chisq.test(response, chemo, correct = FALSE)$p.value)

```

This shows that regime b is better for men (`r inline_text(chitable_men, variable = "response", level = "1", column = "1")` vs `r inline_text(chitable_men, variable = "response", level = "1", column = "0")` response rate, p=`r style_pvalue(chip1$p[chip1$sex == 0])`). For women, there doesn't seem to be a difference between groups. The next thing to check is whether sex in general makes a difference to response:

```{r week58, warning = FALSE}

# Create two-way table of response by sex
tbl_summary(
  lesson5g %>% select(response, sex),
  by = sex,
  type = list(response = "categorical")
)

# Test for a difference in response by sex using chi-squared test
table(lesson5g$response, lesson5g$sex) %>%
  chisq.test(correct = FALSE)

```

This shows similar response rates (around 40-45%) for men and women.

Now we want to test for interaction between chemo regime and sex in a multivariable regression. You can put the interaction directly into the multivariable model:

```{r week59}

# Create logistic regression model for response including interaction between sex and chemo
sex_int_model <- glm(response ~ sex + chemo + sex*chemo,
                     data = lesson5g,
                     family = "binomial")
tbl_regression(sex_int_model, exponentiate = TRUE)

```

By the way, don't try `glm(response ~ sex*chemo, ...)`, that is, including only the interaction term. This would involve a non-randomized comparison between men and women who received the same chemotherapy treatment.

You can repeat this for age by creating a new variable based on the median age:

```{r week510}

# First, get the median age
skim(lesson5g$age)

# Then, create a category variable based on median age
lesson5g <-
  lesson5g %>%
  mutate(
    hiage = if_else(age > 42.5, 1, 0)
  )

```

Then do the subgroup analysis as above:

```{r week511}

# For younger patients
tbl_summary(
  lesson5g %>% filter(hiage == 0) %>% select(response, chemo),
  by = chemo,
  type = list(response = "categorical")
)

# For older patients
tbl_summary(
  lesson5g %>% filter(hiage == 1) %>% select(response, chemo),
  by = chemo,
  type = list(response = "categorical")
)

# Calculate p-value for each comparison
lesson5g %>%
  filter(!is.na(age)) %>% # Exclude 2 patients missing age
  group_by(hiage) %>%
  summarize(p = chisq.test(response, chemo, correct = FALSE)$p.value)

```

There do not appear to be any differences between groups. Now to do the interaction analysis, you can create an interaction term in one of two ways ("chemo\*age" or "chemo\*hiage").

```{r week512, results = "asis"}

# Logistic regression model with interaction between chemo and age (continuous)
age_int_model1 <-
  glm(response ~ chemo + age + chemo*age,
      data = lesson5g,
      family = "binomial")
tbl_regression(age_int_model1, exponentiate = TRUE)

```

```{r week513, results = "asis"}

# Logistic regression model with interaction between chemo and hiage (binary)
age_int_model2 <-
  glm(response ~ chemo + hiage + chemo*hiage,
      data = lesson5g,
      family = "binomial")
tbl_regression(age_int_model2, exponentiate = TRUE)

```

```{r week514, echo = FALSE, purl = FALSE}

chitable_lowage <-
  tbl_summary(
    lesson5g %>% filter(hiage == 0) %>% select(chemo, response),
    by = chemo,
    type = list(response = "categorical"),
    statistic = list(response = "{p}%")
  )

chitable_hiage <-
  tbl_summary(
    lesson5g %>% filter(hiage == 1) %>% select(chemo, response),
    by = chemo,
    type = list(response = "categorical"),
    statistic = list(response = "{p}%")
  )

```

Whichever one you choose, the interaction is non-significant in a logistic regression with age and chemotherapy. Incidentally, you must put age in the model because, not surprisingly, it is statistically significant, with higher age being associated with a lower chance of response.

Incidentally, I have often emphasized the importance of including an estimate and a 95% confidence interval in any set of results rather than just saying "differences between groups were / were not significant". Interaction analyses are somewhat of an exception to this general rule. First, these tend to be secondary, exploratory analyses. Secondly, interaction is rather rare in medicine: treatments tend to work (or not work) regardless of a patient's age, gender, race and so on. Thirdly, the coefficient for the interaction term can be quite difficult to interpret. So it is often appropriate just to say that you looked for an interaction and didn't find one. A model answer might be:

<div class="quote-container">

>[Describe main comparison between chemo regimens here. Describe age and sex here.] In a subgroup analysis, there appeared to be a differential effect of the two regimens depending on sex. In men, response rates were higher for regimen B (`r inline_text(chitable_men, variable = "response", level = "1", column = "1")`) than regimen A (`r inline_text(chitable_men, variable = "response", level = "1", column = "0")`); response rates were more similar in women, though perhaps favoring regimen A (`r inline_text(chitable_women, variable = "response", level = "1", column = "0")` vs. `r inline_text(chitable_women, variable = "response", level = "1", column = "1")`). Sex and sex by regimen interaction were entered into a logistic regression model of regimen and response, but the interaction term was non-significant (p=`r style_pvalue(tbl_regression(sex_int_model, exponentiate = TRUE)$table_body$p.value[[3]])`). There were no apparent differences in response depending on age: response rates were `r inline_text(chitable_lowage, variable = "response", level = "1", column = "1")` v. `r inline_text(chitable_lowage, variable = "response", level = "1", column = "0")` in patients aged below the median compared to `r inline_text(chitable_hiage, variable = "response", level = "1", column = "1")` v. `r inline_text(chitable_hiage, variable = "response", level = "1", column = "0")` in patients aged above the median. The interaction between regimen and age as a continuous variable was non-significant (p=`r style_pvalue(tbl_regression(age_int_model1, exponentiate = TRUE)$table_body$p.value[[3]])`).

</div>

### lesson5h

**PSA is used to screen for prostate cancer. In this dataset, the researchers are looking at various forms of PSA (e.g. "nicked" PSA). What variables should be used to try to predict prostate cancer? How accurate would this test be?**

```{r week515, echo = FALSE, message = FALSE, warning = FALSE, purl = FALSE}

psa_model <- glm(cancer ~ psa + psan + psai + psant,
                 data = lesson5h,
                 family = "binomial")
tbl_psa_model <- tbl_regression(psa_model, exponentiate = TRUE)

tbl_psa <-
  lesson5h %>%
  select(-cancer) %>%
  tbl_summary(
    label = list(psa = "Total PSA (ng/mL)",
                 psan = "Nicked PSA (ng/mL)",
                 psai = "Intact PSA (ng/mL)",
                 psant = "Nicked-to-total ratio")
  )

pred_psa <-
  augment(
    psa_model, type.predict = "response"
  )

auc_psa <- auc(pred_psa$cancer, pred_psa$.fitted)

nont_model <- glm(cancer ~ psa + psan + psai,
                  data = lesson5h,
                  family = "binomial")

pred_nont <-
  augment(nont_model, type.predict = "response")

auc_nont <- auc(pred_nont$cancer, pred_nont$.fitted)

pred_noi <-
  augment(
    glm(cancer ~ psa + psan,
        data = lesson5h,
        family = "binomial"),
    type.predict = "response"
  )

auc_noi <- auc(pred_noi$cancer, pred_noi$.fitted)

```

One approach to selecting which variables to include in a predictive model would be to do a regression. You could start with all the variables.

```{r week515a}

# Model with all variables
glm(cancer ~ psa + psan + psai + psant, data = lesson5h, family = "binomial") %>%
  tbl_regression(exponentiate = TRUE)

```

You might notice that "psant" is not a good predictor (p=`r style_pvalue(tbl_psa_model$table_body$p.value[[4]])`) and decide to take it out of the model.

```{r week515b}

# Model excluding "psant"
glm(cancer ~ psa + psan + psai, data = lesson5h, family = "binomial") %>%
  tbl_regression(exponentiate = TRUE)

```

In a regression using the remaining three variables, "psai" is not statistically significant, and you might then want to remove that variable too.

```{r week515c}

# Model excluding "psant" and "psai"
glm(cancer ~ psa + psan, data = lesson5h, family = "binomial") %>%
  tbl_regression(exponentiate = TRUE)

```

Both "psa" and "psan" are highly predictive, so you could leave them in the model and use the `roc` function to get the area-under-the-curve.

```{r week515d, message = FALSE}

# Save out final model
final_model <-
  glm(cancer ~ psa + psan, data = lesson5h, family = "binomial")

# Get predicted probabilities from final model
final_model_pred <-
  augment(final_model, type.predict = "response")

# Get AUC
roc(cancer ~ .fitted, data = final_model_pred)

```

However, I would have my doubts about such an approach. What you are trying to do here is predict the presence of cancer as well as you can: the significance or otherwise of individual variables doesn’t really come into it. How I would go about my analysis would be in terms of the area-under-the-curve of the models.

```{r week515e, message = FALSE}

# Full model
model1 <- glm(cancer ~ psa + psan + psai + psant, data = lesson5h, family = "binomial")
model1_pred <- augment(model1, type.predict = "response")
roc(cancer ~ .fitted, data = model1_pred)

# Model without "psant"
model2 <- glm(cancer ~ psa + psan + psai, data = lesson5h, family = "binomial")
model2_pred <- augment(model2, type.predict = "response")
roc(cancer ~ .fitted, data = model2_pred)

# Model without "psant" or "psai"
model3 <- glm(cancer ~ psa + psan, data = lesson5h, family = "binomial")
model3_pred <- augment(model3, type.predict = "response")
roc(cancer ~ .fitted, data = model3_pred)

```

So a model answer might be:

<div class="quote-container">

>The cohort consisted of `r nobs(psa_model)` patients. Values for PSA and PSA subtypes are shown in the table. Entering all four PSA variables into a logistic model to predict the presence of prostate cancer gave an area-under-the-curve (AUC) of `r style_sigfig(auc_psa, digits = 3)`. Nicked-to-total ratio was not a strong predictor and removing it from the model did not decrease AUC (`r style_sigfig(auc_nont, digits = 3)`). Removing intact PSA from the model had a small but noticeable impact on AUC (`r style_sigfig(auc_noi, digits = 3)`). We therefore recommend that further research use total, nicked and intact PSA to predict prostate cancer.

</div>

<br>

<center> **Table 1. Marker distributions** </center>

```{r week516, echo = FALSE, results = "asis", purl = FALSE}

tbl_psa

```

<center> **Table 2. Multivariable prediction model** </center>

```{r week517, echo = FALSE, results = "asis", purl = FALSE}

tbl_regression(nont_model,
               exponentiate = TRUE,
               label = list(psa = "Total PSA",
                            psan = "Nicked PSA",
                            psai = "Intact PSA"))

```

### lesson5i

**This is a randomized trial of behavioral therapy in cancer patients with depressed mood. Patients are randomized to no treatment (group 1), informal contact with a volunteer (group 2) or behavior therapy with a trained therapist (group 3). What would you conclude about the effectiveness of these treatments?**

One approach to these data is to use a test called ANOVA. This addresses the question of whether there is some overall difference between the three groups, or, more specifically, tests the null hypothesis that the three groups are equivalent. But this isn’t a very interesting hypothesis. The other thing to do would be to conduct t-tests on all possible pairs (i.e. no treatment vs. therapy; therapy vs. volunteer; volunteer vs. no treatment). But I am not sure that this is particularly interesting either.

What I would use is a regression analysis.

```{r week518}

# Create variables for treatment (yes/no) and therapy (yes/no)
lesson5i <-
  lesson5i %>%
  mutate(
    treat = if_else(group > 1, 1, 0),
    therapy = if_else(group == 3, 1, 0),
  )

# Create linear regression model for followup
treat_model <- lm(followup ~ baseline + treat + therapy,
                  data = lesson5i)
tbl_regression(treat_model)

```

What this does is to create two dummy variables "treat" and "therapy". "treat" means that you had some kind of treatment, whether that was contact with the therapist or just with a volunteer. "therapy" means you saw the trained therapist. So the groups are coded:

```{r week519, echo = FALSE, results = "asis", purl = FALSE}

tbl_5i <-
  tribble(
    ~Group, ~treat, ~therapy,
    "No treatment", 0, 0,
    "Volunteer", 1, 0,
    "Trained therapy", 1, 1
  ) %>%
  gt()

tbl_5i

lesson5i_diff <-
  lesson5i %>%
  mutate(
    diff = followup - baseline
  ) %>%
  select(diff, group) %>%
  group_by(group) %>%
  summarize(mean = mean(diff, na.rm = TRUE),
            sd = sd(diff, na.rm = TRUE))

```

Now when you regress the change score using the variables "treat" and "therapy" you get an estimate of the effect of just spending time with someone and the effect of seeing a trained professional. In my view, this fits in well with the original study design. A model answer might be:

<div class="quote-container">

> Mood scores improved in the therapist group (`r style_sigfig(lesson5i_diff$mean[[3]], digits = 2)` points, SD `r style_sigfig(lesson5i_diff$sd[[3]], digits = 2)`) and volunteer groups (`r style_sigfig(lesson5i_diff$mean[[2]], digits = 2)`, SD `r style_sigfig(lesson5i_diff$sd[[2]], digits = 2)`) but not in the no treatment group (`r style_sigfig(abs(lesson5i_diff$mean[[1]]), digits = 1)` point worsening in score, SD `r style_sigfig(lesson5i_diff$sd[[1]], digits = 2)`). Interaction with a considerate individual appears to improve mood by `r inline_text(tbl_regression(treat_model), variable = "treat", pattern = "{estimate} points ({conf.level*100}% CI {conf.low}, {conf.high}, {p.value})")` with active behavior therapy further improving scores an additional `r inline_text(tbl_regression(treat_model), variable = "therapy", pattern = "{estimate} points ({conf.level*100}% CI {conf.low}, {conf.high}, {p.value})")`.

</div>

## Week 6

```{r loadpkgs6, echo = TRUE}

# Week 6: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 6: load data
lesson6a <- readRDS(here::here("Data", "Week 6", "lesson6a.rds"))
lesson6b <- readRDS(here::here("Data", "Week 6", "lesson6b.rds"))
lesson6c <- readRDS(here::here("Data", "Week 6", "lesson6c.rds"))
lesson6d <- readRDS(here::here("Data", "Week 6", "lesson6d.rds"))

```

### lesson6a and lesson6b

**These are data on a blood test (creatine kinase) to detect a recent myocardial infarct. The two datasets are from a coronary care unit population (06b) and a general hospital population (06c). What is the sensitivity, specificity, positive predictive value and negative predictive value?**

```{r week6a1, echo = FALSE, warning = FALSE, results = "asis", purl = FALSE}

ss_6a <-
  table(
    factor(lesson6a$cktest, levels = c(1, 0)),
    factor(lesson6a$mi, levels = c(1, 0))
  )

tbl_ss6a <-
  tibble(epi.tests(ss_6a)$detail)

ss_6b <-
  table(
    factor(lesson6b$cktest, levels = c(1, 0)),
    factor(lesson6b$mi, levels = c(1, 0))
  )

tbl_ss6b <-
  tibble(epi.tests(ss_6b)$detail)

tbl_ss <-
  tibble(
    test = c("se", "sp", "pv.pos", "pv.neg")
  ) %>%
  mutate(
    value_6a =
      round(
        map_dbl(
          test,
          ~ tbl_ss6a %>%
            filter(statistic == str_glue("{..1}")) %>%
            pull(est)
        ) * 100, 0),
    value_6b =
      round(
        map_dbl(
          test,
          ~ tbl_ss6b %>%
            filter(statistic == str_glue("{..1}")) %>%
            pull(est)
        ) * 100, 0)
  ) %>%
  mutate(
    test =
      case_when(
        test == "se" ~ "Sensitivity",
        test == "sp" ~ "Specificity",
        test == "pv.pos" ~ "Positive Predictive Value",
        test == "pv.neg" ~ "Negative Predictive Value"
      )
  ) %>%
  gt %>%
  cols_label(
    test = "",
    value_6a = "Coronary Care Population",
    value_6b = "General Hospital Population"
  )

```

```{r week6a2, echo = FALSE}

tbl_ss

```

The thing to take away from this is that sensitivity and specificity don’t change, but the positive and negative predictive value do. The prevalence of myocardial infarct is obviously much lower in the general hospital population compared to the coronary care population. So negative predictive value is higher in general patients (you are unlikely to have an MI anyway, so if the test says you’re negative, it is almost definite) and positive predictive value higher in coronary care patients (you are at high risk of having an MI, so a positive test just about confirms it).

### lesson6c

**Here are the data from a study of a marker to predict the results of biopsy for cancer. There are 2000 patients, half of whom had a suspicious imaging result and were biopsied. It is known that only about half of patients with abnormal imaging actually have cancer and that is what is found in this study. The marker was measured in patients undergoing biopsy. Might the new marker help decide which patients with abnormal scans should receive biopsy?**

You might be tempted just to try:

```{r week6b, message = FALSE}

# Calculate AUC for marker predicting cancer using marker
roc(cancer ~ marker, data = lesson6c)

```

You'd get an AUC of `r style_sigfig(auc(roc(cancer ~ marker, data = lesson6c)), digits = 3)`, which is pretty good. But the question isn't "how good is the marker?" but "might the new marker help make a clinical decision about biopsy?" So we need to look at clinical consequences.

Let's try:

```{r week6c, warning = FALSE}

# Here we will drop observations missing marker data from the table (filter function)
tbl_summary(
  lesson6c %>% filter(!is.na(marker)) %>% select(cancer, marker),
  by = marker,
  type = list(cancer = "categorical")
)

```

So you can see that, if you only biopsied patients who were positive for the marker, you do 600 fewer biopsies per 1000, but you’d also miss 200 cancers. That is a lot of cancers to miss and so you might feel that using the marker to make biopsy decisions would do more harm than good. 

### lesson6d

**This is a dataset of cancer patients undergoing surgery with the endpoint of recurrence within 5 years. Since this cohort was established, adjuvant therapy has been shown to be of benefit. Current guidelines are that adjuvant therapy should be considered in patients with stage 3 or high grade disease. Recently, two new variables have been added to the dataset:  levels of a novel tumor marker were obtained from banked tissue samples and preoperative imaging scans were retrieved and scored from 0 (no evidence of local extension) to 4 (definite evidence of local extension). Here are some questions about these data:**

- **How good is the current method for determining whether patients should be referred to adjuvant therapy?**
- **It has been suggested that a statistical model using stage and grade would be better than the current risk grouping. How good do you think this model would be?**
- **Does the marker add information to the model of stage and grade?**
- **Does imaging add information to the model including stage, grade and the marker?**

The first question concerns the value of the current method of determining referral for adjuvant therapy. There are two ways of thinking about this. The first is to show a simple table:

```{r week6d}

# Two-way table of recurrence by hi_risk
tbl_summary(
  lesson6d %>% select(recurrence, hi_risk),
  by = hi_risk,
  type = list(recurrence = "categorical")
)

```

```{r week6e, echo = FALSE, warning = FALSE, message = FALSE, purl = FALSE}

tbl_recur <-
  tbl_summary(
    lesson6d %>% select(recurrence, hi_risk),
    by = hi_risk,
    type = list(recurrence = "categorical"),
    statistic = list(recurrence = "{p}%")
  )

auc_recur <- as.numeric(auc(roc(recurrence ~ hi_risk, data = lesson6d)))

```

You can see that `r inline_text(tbl_recur, variable = "recurrence", level = "1", column = "1")` of patients who met high risk criteria recurred compared to only `r inline_text(tbl_recur, variable = "recurrence", level = "1", column = "0")` of those who were not high stage or high grade. Another way to think about "how good" the criterion is would be to look at discriminative accuracy.

```{r week6f, message = FALSE}

# Calculate AUC for prediction of recurrence using hi_risk
roc(recurrence ~ hi_risk, data = lesson6d)

```

The area-under-the-curve (AUC) is `r style_sigfig(auc_recur)`. Because high risk is a binary variable, this AUC is equivalent to sensitivity plus specificity – 1 (you can check this if you like). 

So now let’s look at the statistical model of stage and grade. We'll first create this model and then use the model to give us the predicted probabilities for each patient.

```{r week6g, message = FALSE}

# Create the model
# "grade" is a categorical variable, so use "factor()"
recur_model <- glm(recurrence ~ stage + factor(grade_numeric),
                   data = lesson6d,
                   family = "binomial")

# Get the predicted probability for each patient
lesson6d_pred <-
  augment(
    recur_model,
    newdata = lesson6d,
    type.predict = "response",
    se = TRUE
  ) %>%
  # Renaming to identify each prediction separately
  rename(clinpred = .fitted, clinpred_se = .se.fit)

# Calculate the AUC for the clinical model
roc(recurrence ~ clinpred, data = lesson6d_pred)

```

So the AUC is better for the model than for simple risk grouping. But would using a model make a clinical difference? The first thing to think about is the sort of risk that would make you consider the use of adjuvant therapy. Clearly a patient with a 1% risk of recurrence should not be referred for adjuvant; a risk of 90% would definitely be an indication for chemotherapy. Somewhere in between 1% and 90%, we’d think that the risk becomes high enough to warrant adjuvant therapy. Let’s imagine that we choose a risk threshold of 10%. We can now do this.

```{r week6h}

# Create a new variable to define patients at high risk from the model
lesson6d_pred <-
  lesson6d_pred %>%
  mutate(
    clinmodel_hirisk = if_else(clinpred >= 0.1, 1, 0)
  )

# Compare who is defined as high risk from the model
# with those defined as high risk using clinical criteria
tbl_summary(
  lesson6d_pred %>% select(clinmodel_hirisk, hi_risk),
  by = hi_risk,
  type = list(clinmodel_hirisk = "categorical")
)

```

You can see that no patient is "reclassified" using the model. All 2200 patients defined as high risk by clinical criteria are also defined as high risk (risk ≥10%) by the model, similarly, all 4,375 patients defined as low risk by clinical criteria have risks <10% from the model.

How about adding in the marker?

```{r week6i, message = FALSE}

# Create the model
marker_recur_model <- glm(recurrence ~ stage + factor(grade_numeric) + marker,
                          data = lesson6d,
                          family = "binomial")
tbl_regression(marker_recur_model, exponentiate = TRUE)

# Get the predicted probability for each patient
lesson6d_pred <-
  augment(
    marker_recur_model,
    newdata = lesson6d_pred,
    type.predict = "response",
    se = TRUE
  ) %>%
  rename(markerpred = .fitted, markerpred_se = .se.fit)

# Calculate the AUC from the marker for the marker model
roc(recurrence ~ markerpred, data = lesson6d_pred)

```

```{r week6j, echo = FALSE, message = FALSE, warning = FALSE, purl = FALSE}

clin_auc <- as.numeric(auc(roc(recurrence ~ clinpred, data = lesson6d_pred)))

marker_auc <- as.numeric(auc(roc(recurrence ~ markerpred, data = lesson6d_pred)))

```

A couple of things to note here. First, the marker is a statistically significant predictor in the model. Typical language is that the marker is "an independent predictor" or that "it is significant after adjusting for stage and grade". Second, it increases AUC quite a bit, from `r style_sigfig(clin_auc, digits = 3)` for the clinical variables alone to `r style_sigfig(marker_auc, digits = 3)` for the clinical variables plus the marker. But let's again look at clinical consequences.

```{r week6k}

# Identify patients at >= 10% risk from clinical+marker model
lesson6d_pred <-
  lesson6d_pred %>%
  mutate(markermodel_hirisk = if_else(markerpred >= 0.1, 1, 0))

# Compare who is defined as high risk from the clinical+marker model
# with those defined as high risk using clinical criteria
tbl_summary(
  lesson6d_pred %>% select(markermodel_hirisk, hi_risk),
  by = hi_risk,
  type = list(markermodel_hirisk = "categorical")
)

```

```{r week6l, echo = FALSE, purl = FALSE}

tbl_markermodel <-
  tbl_summary(
    lesson6d_pred %>% select(markermodel_hirisk, hi_risk),
    by = hi_risk,
    type = list(markermodel_hirisk = "categorical"),
    statistic = list(markermodel_hirisk = "{n}")
  )

tbl_recur1 <-
  tbl_summary(
    lesson6d_pred %>% filter(markermodel_hirisk == 1 & hi_risk == 0) %>%
      select(recurrence),
    type = list(recurrence = "categorical"),
    statistic = list(recurrence = "{p}%")
  )

tbl_recur2 <-
  tbl_summary(
    lesson6d_pred %>%
      filter(markermodel_hirisk == 0 & hi_risk == 1) %>%
      select(recurrence),
    type = list(recurrence = "categorical"),
    statistic = list(recurrence = "{p}%")
  )

```

You can see now that `r inline_text(tbl_markermodel, variable = "markermodel_hirisk", level = "0", column = "1")` patients who would otherwise be referred to adjuvant chemotherapy would not using the model, and `r inline_text(tbl_markermodel, variable = "markermodel_hirisk", level = "1", column = "0")` of those defined at low risk by the clinical criteria are reclassified as high risk from the model (presumably because of a high level of the marker). You could also do this:

```{r week6m}

# Table of recurrences for those at high risk from the marker model but not clinically
tbl_summary(
  lesson6d_pred %>%
    filter(markermodel_hirisk == 1 & hi_risk == 0) %>%
    select(recurrence),
  type = list(recurrence = "categorical")
)

# Table of recurrences for those at low risk from the marker model but high risk clinically
tbl_summary(
  lesson6d_pred %>%
    filter(markermodel_hirisk == 0 & hi_risk == 1) %>%
    select(recurrence),
  type = list(recurrence = "categorical")
)

```

You can see that patients reclassified as low risk using the marker really are at low risk (only `r inline_text(tbl_recur2, variable = "recurrence", level = "1")` of them recurred) whereas `r inline_text(tbl_recur1, variable = "recurrence", level = "1")` of those defined as high risk from the model did indeed recur. As to whether you’d use this in practice, the question is whether it is worth measuring the marker on ~6500 to reclassify ~500. That all depends on how difficult, invasive and expensive it is to measure the marker. 

As for imaging, if you try:

```{r week6n, message = FALSE}

# Create model that includes imaging score
imaging_model <- glm(recurrence ~ stage + factor(grade_numeric) + marker + imaging_score,
                     data = lesson6d,
                     family = "binomial")

# Get predictions for imaging model
lesson6d_pred <-
  augment(
    imaging_model,
    newdata = lesson6d_pred,
    type.predict = "response",
    se = TRUE
  ) %>%
  rename(imagingpred = .fitted, imagingpred_se = .se.fit)

# Calculate AUC for imaging model
roc(recurrence ~ imagingpred, data = lesson6d_pred)

```

```{r week6o, echo = FALSE, message = FALSE, purl = FALSE}

imaging_auc <- as.numeric(auc(roc(recurrence ~ imagingpred, data = lesson6d_pred)))

```

You'll find that imaging is a statistically significant predictor of recurrence, even after adjusting for stage, grade and the marker, but it doesn’t improve AUC by very much (from `r style_sigfig(marker_auc, digits = 3)` to `r style_sigfig(imaging_auc, digits = 3)`). You could go on to see that it also doesn’t reclassify very well.

```{r week6p}

# Create variable indicating whether patient is high risk from imaging model
lesson6d_pred <-
  lesson6d_pred %>%
  mutate(
    imagingmodel_hirisk = if_else(imagingpred >= 0.1, 1, 0)
  )

# Two-way table of high risk status, based on marker model and imaging model
tbl_summary(
  lesson6d_pred %>%
    select(imagingmodel_hirisk, markermodel_hirisk),
  by = markermodel_hirisk,
  type = list(imagingmodel_hirisk = "categorical")
)

```

```{r week6q, echo = FALSE, results = "hide", purl = FALSE}

tbl_imaging <-
  tbl_summary(
    lesson6d_pred %>%
      select(imagingmodel_hirisk, markermodel_hirisk),
    by = markermodel_hirisk,
    type = list(imagingmodel_hirisk = "categorical"),
    statistic = list(imagingmodel_hirisk = "{n}")
  )

imaging_table_body <- tbl_imaging$table_body

imaging_reclass <-
  as.numeric(imaging_table_body$stat_1[imaging_table_body$label == "1"]) +
  as.numeric(imaging_table_body$stat_2[imaging_table_body$label == "0"])

```

You'll see that only `r imaging_reclass` patients are reclassified. It is questionable whether we'd want to do scans on ~`r round(nrow(lesson6d), -2)` patients to reclassify `r imaging_reclass` of them.

And here are the answers to the questions without data!

### lesson6e

**Hospitalized neutropenic patients were randomized to receive drug a or placebo. Bloods were taken every day. The time until patients were no longer neutropenic was measured (all patients eventually did get better).**

A possible answer might be:

<div class="quote-container">

>Mean time to recovery was ?? (SD ??) in the ?? patients randomized to drug a, compared to ?? (SD ??) in the ?? patients receiving placebo. The difference between means of ?? fewer / more days with neutropenia (95% C.I. ??, ??) was / was not statistically significant (p=??).

</div>

If the data were very skewed, which wouldn’t be uncommon for data of this sort, we might try the following, although obtaining a 95% confidence interval for the difference between medians is not straightforward. 

<div class="quote-container">

>Median time to recovery was ?? (interquartile range ?? - ??) in the ?? patients randomized to drug a, compared to ?? (interquartile range ?? - ??) in the ?? patients receiving placebo. The difference between medians of ?? fewer / more days with neutropenia (95% C.I. ??, ??) was / was not statistically significant (p=??). 
</div>

### lesson6f

**A new lab machine sometimes fails to give a readout with the result that the sample is wasted. To try and get a handle on this problem, a researcher carefully documents the number of failures for the 516 samples that she analyzes in the month of September.**

This is a simple one:

<div class="quote-container">

>Of the 516 samples analyzed in September, ?? led to a failed readout (??%, 95% C.I. ??%, ??%).

</div>

### lesson6g

**Drug a appears to be effective against cancer cells in vitro. Researchers create two new drugs, b and c, by making slight molecular rearrangements of drug a. The three drugs are then added to tumor cells in the test tube and the degree of cell growth measured.**

The key thing to think about here is the comparisons you want to make. Drug a already is known to work, so what you want to know is whether drug b or c might be more effective. So you want the comparison between drug a and b and between drug a and c, not between drug b and c. Hence you might have something like:

<div class="quote-container">

>Mean cell growth was ?? (SD??), ?? (SD??) and ?? (SD??) in cells treated by drugs a, b and c respectively. Drug b was more / less effective than drug a (difference between mean cell growth ??; 95% C.I. ??, ??). Drug c was more / less effective than drug a (difference between mean cell growth ??; 95% C.I. ??, ??).

</div>

## Week 7

```{r loadpkgs7, echo = TRUE}

# Week 7: load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Week 7: load data
lesson7a <- readRDS(here::here("Data", "Week 7", "lesson7a.rds"))
lesson7b <- readRDS(here::here("Data", "Week 7", "lesson7b.rds"))
lesson7c <- readRDS(here::here("Data", "Week 7", "lesson7c.rds"))
lesson7d <- readRDS(here::here("Data", "Week 7", "lesson7d.rds"))

```

### lesson7a

**This is a large set of data on patients receiving adjuvant therapy after surgery for colon cancer. Describe this dataset and determine which, if any, variables are prognostic in this patient group.**

The data list the number of days of follow-up (survival_time), whether the patient was dead or alive at last follow-up (died), sex, age and various characteristics of the colon tumor.

We can use `survfit` and `skim` to get the median time for all patients and for survivors only. Remember to use the `Surv` function to specify your event status and time to event.

```{r week7b}

# Median followup for all patients
survfit(Surv(survival_time, died) ~ 1, data = lesson7a)

# Median followup for survivors
lesson7a %>%
  filter(died == 0) %>%
  skim(survival_time)

```

To look at predictors of survival, we might conduct a multivariable regression:

```{r week7c}

# Multivariable Cox model for time to death
coxph(Surv(survival_time, died) ~ sex + age + obstruction + perforation + adhesions + nodes,
      data = lesson7a) %>%
  tbl_regression(exponentiate = TRUE)

```

This suggests that the presence of obstruction or adhesion influences survival, as well as the number of nodes. Neither age (surprisingly) nor sex are likely to have a large impact (the confidence interval does not include any large differences between groups). The p-value for perforation is non-significant, but the confidence intervals are wide. Why is this? Try this:

```{r week7d}

# Table of perforation rate
tbl_summary(
  lesson7a %>% select(perforation)
)

```

You will see that less than 3% of patients had perforations, making it almost impossible to assess its predictive value. Another useful thing to do is to try:

```{r week7e}

# Summarize number of nodes
lesson7a %>%
  skim(nodes)

```

You can see that patients had up to 33 nodes affected, yet all but a handful had 10 or fewer nodes. This might make us somewhat suspicious of the coefficient for nodes (which is interpreted as increase in hazard ratio for each additional node). One possibility might be to cap the number of nodes. This creates a new variable that caps the number of nodes at 10. Since fewer than 3% of patients had perforations, we will exclude this variable from our model.

```{r week7f}

# Create new nodes variable, capped at 10 nodes
lesson7a <-
  lesson7a %>%
  mutate(
    n2 = 
      case_when(
        nodes <= 10 ~ nodes,
        nodes > 10 ~ 10
        )
    )

# Re-run cox model using "n2" (which caps the number of nodes at 10)
coxph(Surv(survival_time, died) ~ sex + age + obstruction + adhesions + n2,
      data = lesson7a) %>%
  tbl_regression(exponentiate = TRUE)

```

However, it might be better to group patients. Here we create a new variable called "node4" that groups patients into four groups: 0 – 2 nodes, 3 – 5 nodes, 5 – 10 nodes, 11 or more nodes.

```{r week7g}

# Categorize values of nodes removed
lesson7a <-
  lesson7a %>%
  mutate(
    node4 =
      case_when(
        nodes <= 2 ~ 1,
        nodes > 2 & nodes <= 5 ~ 2,
        nodes > 5 & nodes <= 10 ~ 3,
        nodes > 10 ~ 4
      )
  )

```

The "cut-points" are arbitrary but are not particularly important unless you think the effect of nodes radically changes at one particular cut point or another.

The regression code would then be:

```{r week7h}

# Re-run Cox model using categorized variable for nodes
# Since "node4" is categorical, we must use "factor()" with this variable
coxph(Surv(survival_time, died) ~ sex + age + obstruction + adhesions + factor(node4),
      data = lesson7a)

```

```{r week7i, echo = FALSE, warning = FALSE, purl = FALSE}

survfit_7a <- survfit(Surv(lesson7a$survival_time/365.25, lesson7a$died) ~ 1)

median_surv <-
  (lesson7a %>%
     filter(died != 1) %>%
     skim(survival_time) %>%
     pull(numeric.p50)
  ) / 365.25

tbl_summary_7a <-
  tbl_summary(
    lesson7a %>%
      mutate(node4 = factor(node4, labels = c("0-2", "3-5", "5-10", ">10"))) %>%
      select(sex, age, obstruction, adhesions, node4),
    type = list(c(sex, obstruction, adhesions) ~ "dichotomous"),
    label = list(sex = "Female", age = "Age", node4 = "Number of Nodes",
                 obstruction = "Obstruction", adhesions = "Adhesions")
  )

tbl_cox_7a <-
  coxph(Surv(survival_time, died) ~ sex + age + obstruction + adhesions + factor(node4),
        data = lesson7a %>%
                mutate(node4 = factor(node4, labels = c("0-2", "3-5", "5-10", ">10")))) %>%
  tbl_regression(
    exponentiate = TRUE,
    label = list(sex = "Female", age = "Age (per 1 year)",
                 obstruction = "Obstruction", adhesions = "Adhesions",
                 "factor(node4)" = "Number of Nodes")
  )

```

A model answer for this dataset might be:

<div class="quote-container">

>Median survival in the `r survfit_7a$n` patients in the cohort was `r style_sigfig(as.numeric(summary(survfit_7a)$table["median"]))` years, with a median duration of follow-up for survivors of `r style_sigfig(median_surv)` years. There were `r sum(survfit_7a$n.event)` deaths during follow-up. Although about 95% of patients had ten nodes or fewer, a small number of patients had a very large number of affected nodes, up to `r max(lesson7a$nodes, na.rm = TRUE)` in one case. Nodes were therefore categorized as 0-2, 3-5, 6-10, and >10. In a Cox regression of the `r tbl_cox_7a$n` patients with complete data, obstruction, adhesion and number of nodes were predictive of survival. Neither sex, age or perforation appeared to influence survival. Fewer than `r round(mean(lesson7a$perforation, na.rm = TRUE)*100, 0)`% of patients experienced perforations and this variable was therefore removed from the model. Patient characteristics and results for the final model are given in the table.

</div>

**Table 1.** Patient Characteristics

```{r week7j, echo = FALSE, results = "asis", purl = FALSE}

tbl_summary_7a

```

**Table 2.** Results of Cox proportional hazards model for time to death

```{r week7k, echo = FALSE, results = "asis", purl = FALSE}

tbl_cox_7a

```

### lesson7b

**These are time to recurrence data on forty patients with biliary cancer treated at one of two hospitals, one of which treats a large number of cancer patients and one of which does not. Do patients treated at a “high volume” hospital have a longer time to recurrence?**

We can test the difference between groups by using the `survdiff` function:

```{r week7l}

# Test for difference in time to recurrence by hivolume
survdiff(Surv(time, recurrence) ~ hivolume, data = lesson7b)

```

```{r week7m, echo = FALSE, purl = FALSE}

survdiff_7b <-
  survdiff(Surv(time, recurrence) ~ hivolume, data = lesson7b)

survdiff_p_7b <- 1 - pchisq(survdiff_7b$chisq, length(survdiff_7b$n) - 1)

```

We get a p-value of `r style_pvalue(survdiff_p_7b)`.

This is not sufficient evidence to conclude that high volume hospitals and more experienced surgeons lower recurrence rates. However, could there be a difference and the trial was not large enough to detect it? The key point here is not sample size, but the number of "events" (typically recurrences or deaths). Even if you had a trial of 100,000 patients, if only one or two people died you would not have any data on length of survival to test. In this dataset, though there were 40 patients, there were only ten events. You can see that if you use the `survfit` function:

```{r week7n}

# Look at number of recurrence events in this dataset
survfit(Surv(time, recurrence) ~ 1, data = lesson7b)

```

You can then look at a Cox model:

```{r week7o}

# Cox model for time to recurrence
lesson7b_cox <-
  coxph(Surv(time, recurrence) ~ hivolume, data = lesson7b)
tbl_regression(lesson7b_cox, exponentiate = TRUE)

```

You find that the hazard ratio for survival is `r inline_text(tbl_regression(lesson7b_cox, exponentiate = TRUE), variable = "hivolume", pattern = "{estimate}")`. The 95% CI is `r inline_text(tbl_regression(lesson7b_cox, exponentiate = TRUE), variable = "hivolume", pattern = "{conf.low}")`, `r inline_text(tbl_regression(lesson7b_cox, exponentiate = TRUE), variable = "hivolume", pattern = "{conf.high}")`. Clearly, high volume hospitals seem to do better, this dataset just isn’t large enough to see it. 

```{r week7p, echo = FALSE, purl = FALSE}

median_surv_7b <-
  (lesson7b %>%
     filter(recurrence != 1) %>%
     skim(time) %>%
     pull(numeric.p50)) / 12

recur_ct <-
  lesson7b %>%
  group_by(hivolume) %>%
  summarize(n = sum(recurrence, na.rm = TRUE))

est_surv <-
  summary(survfit(Surv(lesson7b$time, lesson7b$recurrence) ~ lesson7b$hivolume),
          times = c(183, 365, 548))

```

A model answer:

<div class="quote-container">

>At a median follow-up for survivors of `r style_sigfig(median_surv_7b)` months, `r recur_ct[2, 2]` patients in the high volume hospital had recurred compared to `r recur_ct[1, 2]` in the low volume hospital (Figure 1, p=`r style_pvalue(survdiff_p_7b)` by log-rank test). Median survival has not been reached in either group. The hazard ratio of `r inline_text(tbl_regression(lesson7b_cox, exponentiate = TRUE), variable = "hivolume", pattern = "{estimate} ({conf.level*100}% CI {conf.low}, {conf.high})")` suggests that a large difference between groups may not have been detected at this stage of follow-up.

</div>

**Figure 1.** Kaplan-Meier curve for recurrence in low volume (blue) and high volume (red) centers

```{r week7q, echo = FALSE, results = "asis", purl = FALSE}

plot(survfit(Surv(lesson7b$time, lesson7b$recurrence) ~ lesson7b$hivolume), col = c("blue", "red"))

```

Another way of doing this would be to estimate survival at say, 6, 12 and 18 months in each hospital. The command would be:

```{r week7r}

# Estimate survival at 6, 12 and 18 months
summary(survfit(Surv(time, recurrence) ~ hivolume, data = lesson7b),
        times = c(183, 365, 548))

```

You could report survival of `r est_surv$surv[[4]]*100`%, `r est_surv$surv[[5]]*100`%, and `r round(est_surv$surv[[6]]*100, 0)`% in the high volume hospital compared to `r est_surv$surv[[1]]*100`%, `r est_surv$surv[[2]]*100`% and `r round(est_surv$surv[[3]]*100, 0)`% in the low volume hospital.

### lesson7c

**These are data from a randomized trial comparing no treatment, 5FU (a chemotherapy agent) and 5FU plus levamisole in the adjuvant treatment of colon cancer. Describe the dataset. What conclusions would you draw about the effectiveness of the different treatments?**

```{r week7s, echo = FALSE, warning = FALSE, message = FALSE, results = "hide", purl = FALSE}

survfit_7c <- survfit(Surv(survival_time/365.25, died) ~ treatment, data = lesson7c)

median_surv_7c <-
  (lesson7c %>%
     filter(died != 1) %>%
     skim(survival_time) %>%
     pull(numeric.p50)) / 365.25

style_sigfig(as.numeric(summary(survfit_7c)$table["median"]))

survdiff_7c <- survdiff(Surv(survival_time/365.25, died) ~ group, data = lesson7c)
survdiff_p_7c <- 1 - pchisq(survdiff_7c$chisq, length(survdiff_7c$n) - 1)

lesson7c <-
  lesson7c %>%
  mutate(
    fu = if_else(group == 2, 1, 0),
    lev = if_else(group == 3, 1, 0)
  )
lesson7c %>% count(group, treatment, fu, lev)

lesson7c_cox <-
  coxph(Surv(survival_time/365.25, died) ~ fu + lev, data = lesson7c) %>%
  tbl_regression(exponentiate = TRUE)

#plot(survfit(Surv(survival_time/365.25, died) ~ treatment, data = lesson7c), col = c("blue", "black", "red"))

```

Let's jump straight to the model answer.

<div class="quote-container">

>The study consisted of `r nrow(lesson7c)` patients, of whom `r sum(lesson7c$died, na.rm = TRUE)` died during the study. Median duration of follow-up for survivors was `r style_sigfig(median_surv_7c)` years. Median survival in the control and 5FU groups was `r style_sigfig(summary(survfit_7c)$table[3, "median"])` and `r style_sigfig(summary(survfit_7c)$table[1, "median"])` years, respectively; median survival for the combination group has not been reached (see figure). The overall log-rank test was significant (p=`r style_pvalue(survdiff_p_7c)`), suggesting that the survival is different between groups. In a multivariable Cox regression with group coded as two dummy variables (5FU and Levamisole), 5FU was found to have little effect on survival (HR `r inline_text(lesson7c_cox, variable = "fu")`). Levamisole, however, led to significantly increased survival (HR `r inline_text(lesson7c_cox, variable = "lev")`).

**Figure**

</div>

```{r week7t, echo = FALSE, purl = FALSE}

ggsurvfit::survfit2(Surv(survival_time/365.25, died) ~ treatment, data = lesson7c) %>%
  ggsurvfit::ggsurvfit() +
  labs(
    x = "Survival Time (Years)"
  ) +
  scale_y_continuous(label = scales::percent)

```

In case you are wondering how I did all this, one key is to see that in the dataset "group" and "treatment" are equivalent:

```{r week7u}

# Two-way table of group by treatment
tbl_summary(
  lesson7c %>% select(group, treatment),
  by = treatment
)

```

When I did the graph, I used the variable "treatment" to get the names of the treatments (rather than the group number). I used the {ggsurvfit} package, which allows you to create survival plots using the same type of syntax that is used in plots created using the {ggplot2} package. Here, the `survfit2` function from {ggsurvfit} is used to perform the survival analysis calculations and passed to the `ggsurvfit` function. (The code and options for the `survfit2` function is the same as the `survfit` function.) Survival time was specified as "survival_time/365.25" so that the graph is plotted showing survival time in years, rather than days. The `labs` function allows us to specify an x-axis label, and `scale_y_continuous(label = scales::percent)` formats the y-axis on a scale from 0% to 100%, rather than the default scale from 0 to 1.

```{r week7v, results = "hide"}

# Create Kaplan-Meier plot by treatment group
ggsurvfit::survfit2(Surv(survival_time/365.25, died) ~ treatment, data = lesson7c) %>%
  ggsurvfit::ggsurvfit() +
  labs(
    x = "Survival Time (Years)"
  ) +
  scale_y_continuous(label = scales::percent)

```

When I did the Cox regression, I created dummy variables by typing:

```{r week7w}

# Create dummy variable for treatment
lesson7c <-
  lesson7c %>%
  mutate(
    fu = if_else(group == 2, 1, 0),
    lev = if_else(group == 3, 1, 0)
  )

```

Then it was straightforward to create the cox model and get the overall p-value from the `survdiff` function.

```{r week7x}

# Cox model with dummy variables
coxph(Surv(survival_time, died) ~ fu + lev, data = lesson7c)

# Overall p-value for all 3 groups
survdiff(Surv(survival_time, died) ~ group, data = lesson7c)

```

Any oncologists notice a problem here? It is this: Levamisole doesn’t work at all, but 5FU (obviously) does. It turns out that this whole dataset (which I downloaded from the internet) was miscoded: it should have been: control, levamisole alone, levamisole + 5FU. Which goes to show the importance of checking your data.

### lesson7d

**More data on time to recurrence by hospital volume. Given this dataset, determine whether patients treated at a “high volume” hospital have a longer time to recurrence.**

These data are comparable to **lesson7b**, except with a longer length of follow-up. There are more recurrences (events) because more time has elapsed. So though the hazard ratio is very similar, and the number of patients identical, the confidence interval is much narrower and the results statistically significant. However, do be careful about drawing causal inferences: just because recurrence rates are lower at the high volume hospital, it doesn't mean that treatment at a high volume hospital reduces risk of recurrence. There may be other differences between hospitals (e.g. case mix).

