```{r setup3, include=FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# Set seed
set.seed(34634986)

# To display histograms from "skim"
Sys.setlocale("LC_CTYPE", "Chinese")

# Load data

# Save out list of all files
all_data <-
  list.files(here::here("Data"), pattern = ".rds", recursive = TRUE) %>%
  map(~ glue::glue("Data/{..1}") %>% as.character())

# Give names to list (will be object names)
all_data_names <-
  map(all_data,
      ~ str_split(..1, "/") %>%
        unlist() %>%
        pluck(3) %>%
        str_replace(".rds", "")
      )
names(all_data) <- all_data_names

# Load all data to environment
list2env(map(all_data, readRDS), envir = .GlobalEnv)

```

# Week 3

## Setting up

```{r loadpkgs3, echo = TRUE, warning = FALSE, message = FALSE}

# Load packages
library(skimr)
library(gt)
library(gtsummary)
library(epiR)
library(broom)
library(pROC)
library(gmodels)
library(survival)
library(here)
library(tidyverse)

# The "trial" and "midwest" datasets are available automatically 
# after you load the packages above

# Load other data necessary to run Week 3 examples
lesson1a <- readRDS(here::here("Data", "Week 1", "lesson1a.rds"))
example3a <- readRDS(here::here("Data", "Week 3", "example3a.rds"))

```

## R Instructions

### Hypothesis Testing

For this week's assignment, you will need to learn the following functions:

- `t.test`
- `wilcox.test`
- `binom.test`

#### **t-test**

This is used to compare a continuous outcome (such as hemoglobin) in two groups (e.g. vegetarians and carnivores, or patients in a randomized trial receiving an anemia treatment or placebo). Now statisticians normally say that the t-test makes two assumptions: (1) data are normally distributed and (2) variances are equal. Don’t worry about assumption (2) for now. Also, assumption (1) has an odd feature: it doesn’t matter once sample sizes get large (for those of you who want to boast that you know a "theorem", this is called the "central limit theorem"). Just how large is "large" is a matter of judgment, but generally speaking, it is said that you can feel okay using a t-test on non-normal data once the sample size is above 30 a group. As it turns out, the t-test is "robust" to non-normal data, even if sample sizes are low. "Robust" means that it gives similar results regardless of whether the data are normally distributed or not. So many people feel comfortable using the t-test for to compare a continuous outcome between two groups even if the data are pretty skewed. 

**Different forms of the t-test**

The two main forms of the t-test are "paired" and "unpaired". "Unpaired" is used when, for example, testing marker levels between a drug and placebo group, as there are different patients in each group:

```{r section3a}

# t-test for marker levels between treatment arms
t.test(marker ~ trt, data = trial, var.equal = TRUE)

```

A "paired" test, for example, comparing blood pressure taken before and after an intervention, because you are looking at two observations on the same patient.

<!-- Note: Don't need to specify "var.equal = TRUE" for paired tests, as this is the default, but I thought it might be easier to be consistent across all. -->

```{r section3b}

# paired t-test for blood pressure between "before" and "after" groups
t.test(bp ~ when, data = example3a, var.equal = TRUE, paired = TRUE)

``

A single sample test compares the mean of a group of observations with some hypothetical value, for example, is the average rate of college-educated adults in the midwest different than the national average of 32%?

```{r section3c}

# t-test assessing whether the rate of college education is different than 32%
t.test(midwest$percollege, mu = 32)

```

Let’s look at the print out from a t-test in more detail:

```{r section3e}

# t-test for difference in horsepower for manual vs automatic transmission
t.test(hp ~ am, data = mtcars, var.equal = TRUE)

```

This example is testing whether there is a difference in horsepower (hp) between cars with an automatic transmission (am == 0) vs manual transmission (am == 1).

The `t.test` function reports the data and variables you are testing, following by the t statistic (t), degrees of freedom (df) and p-value. Below that, it states the alternative hypothesis you are testing, prints the mean in each group, and gives the 95% confidence interval around the difference in group means.

While for an unpaired test, the `t.test` command prints the group means in each group, you may want to report the difference between means. The group means are stored in the `t.test` results under `estimate`.

```{r section3f1}

# perform t-test and save out results as "hp_test"
hp_test <- t.test(hp ~ am, data = mtcars, var.equal = TRUE)

# show the group means from "hp_test"
hp_test$estimate

```

To calculate the difference in means between group 0 and group 1, you can use the `estimate` data to calculate this. The square brackets indicate which number (first mean or second mean) to take. This works to calculate the difference between group 0 and group 1, as well as between group 1 and group 0.

```{r section3f2}

# You can save out the means for each group

# The first value is mean in group 0
# ("mean in group 0" is printed first in results)
mean_group0 <- hp_test$estimate[[1]]

# The second value is mean in group 1
mean_group1 <- hp_test$estimate[[2]]

# Subtract the mean in group 1 from the mean in group 0
mean_group0 - mean_group1

# Subtract the mean in group 0 from the mean in group 1
mean_group1 - mean_group0

```

You don't need to worry about the t statistic or degrees of freedom (df). The numbers you are most interested in are the p-value, the group means, and the 95% confidence interval.

Now we haven’t discussed the 95% confidence interval yet, but think of it in simple terms as a plausible range of true values of the difference between means. In this data, the average horsepower is `r round(hp_test$estimate[[1]] - hp_test$estimate[[2]], 1)` higher in cars with an automatic transmission, but it could be that, in fact, the true horsepower is between `r round(abs(hp_test$conf.int[[1]]), 1)` lower or `r round(abs(hp_test$conf.int[[2]]), 1)` higher in the automatic group vs the manual group.

#### **Non-parametric methods**

These are used to compare continuous outcomes in two groups. There are no assumptions about normality or variance. 

Unpaired case, for example, do marker levels differ between the drug and placebo groups?

```{r section3g2}

# non-parametric test for difference in marker levels by treatment group
wilcox.test(marker ~ trt, data = trial, correct = FALSE, paired = FALSE)

```

Paired case, for example, does an intervention cause a change in a patient's blood pressure?

```{r section3h}

# paired non-parametric test for difference in "before" and "after" blood pressure measurements
wilcox.test(bp ~ when, data = example3a, correct = FALSE, paired = FALSE)

```

Single sample, for example, is the rate of college education in the midwest different than the national average (32%)?

```{r section3i}

# non-parametric test - is rate of college education different from 32%?
wilcox.test(midwest$percollege, mu = 32, correct = FALSE)

```

Note here that you don’t get any parameters for the groups such as means, medians or standard deviations. You also don’t get an estimate for the difference between groups.

#### **The binomial test**

The binomial test compares a proportion to a hypothesized value. For example, what is the probability that an unbiased coin thrown 100 times would give a result as or more extreme than 60 heads? (This probability is equivalent to the p value). 

The first argument of `binom.test` is the number of successes, then the number of total tests (total observations). The hypothesized probability is specified by the `p =` option - the default is 0.5 (50%).

```{r section3j}

# Compare a proportion to a hypothesized value "p"
binom.test(60, 100, p = 0.5)

```

You can also use `binom.test` on data from a dataset. For example, if we want to test whether the proportion of women (sex = 1) is different from 50%:

```{r section3k}

# The "sum" function adds up the number of observations where sex == 1 (women)
nwomen <- sum(lesson1a$sex)
nwomen

# The "nrow" function (for "number of rows") counts the total number of observations
ntotal <- nrow(lesson1a)
ntotal

# Compare a proportion of patients in a dataset to a hypothesized value "p"
binom.test(nwomen, ntotal, p = 0.5)

```

```{r section3l, echo = FALSE, purl = FALSE}

sex_test <- binom.test(sum(lesson1a$sex), nrow(lesson1a), p = 0.5)

```

This tells you that you had `r sex_test$parameter` observations, and there were `r sex_test$statistic` where sex was coded as 1, an observation proportion of `r round(sex_test$estimate, 2)`. Now the "assumed" proportion was `r sex_test$null.value`, giving an expected number of `r sex_test$parameter*sex_test$null.value` women. These two values are quite close and the p value is `r style_pvalue(sex_test$p.value)`. 

## Assignments

```{r assignmentdata, eval = TRUE, purl = TRUE}

# Copy and paste this code to load the data for week 3 assignments
lesson3a <- readRDS(here::here("Data", "Week 3", "lesson3a.rds"))
lesson3b <- readRDS(here::here("Data", "Week 3", "lesson3b.rds"))
lesson3c <- readRDS(here::here("Data", "Week 3", "lesson3c.rds"))
lesson3d <- readRDS(here::here("Data", "Week 3", "lesson3d.rds"))
lesson3e <- readRDS(here::here("Data", "Week 3", "lesson3e.rds"))
lesson3f <- readRDS(here::here("Data", "Week 3", "lesson3f.rds"))

```

Again, more questions than you need to do, unless you’re keen (also, most won’t take long). Try to do at least the first three. 

- lesson3a.rds: These are data from over 1000 patients undergoing chemotherapy reporting a nausea and vomiting score from 0 to 10 on the day of treatment.  Does previous chemotherapy increase nausea scores? What about sex? 
- lesson3b.rds: Patients with wrist osteoarthritis are randomized to a new drug or placebo. Pain is measured before and two hours after taking a dose of the drug. Is the drug effective?
- lesson3c.rds: Some postoperative pain data again. Is pain on day 2 different than pain on day 1? Is pain on day 3 different from pain on day 2? 
- lesson3d.rds: This is a single-arm, uncontrolled study of acupuncture for patients with neck pain. Does acupuncture increase range of motion?  Just as many men as women get neck pain. Can we say anything about the sample chosen for this trial with respect to gender? The mean age of patients with neck pain is 58.2 years. Is the trial population representative with respect to age?
- lesson3e.rds: These data are length of stay from two different hospitals. One of the hospitals uses a new chemotherapy regime that is said to reduce adverse events and therefore length of stay. Does the new regime decrease length of stay? 
- lesson3f.rds: These data are from a randomized trial on the effects of physiotherapy treatment on physical function in pediatric patients recovering from cancer surgery. Function is measured on a 100 point scale. Does physiotherapy help improve physical functioning?
